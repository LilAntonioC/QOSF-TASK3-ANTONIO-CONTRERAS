{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dwave-ocean-sdk\n",
      "  Downloading dwave_ocean_sdk-8.0.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dimod==0.12.17 (from dwave-ocean-sdk)\n",
      "  Downloading dimod-0.12.17-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting dwave-cloud-client==0.13.1 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_cloud_client-0.13.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting dwave-gate==0.3.2 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_gate-0.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting dwave-greedy==0.3.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_greedy-0.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting dwave-hybrid==0.6.12 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_hybrid-0.6.12-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting dwave-inspector==0.5.1 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_inspector-0.5.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting dwave-neal==0.6.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_neal-0.6.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dwave-networkx==0.8.15 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_networkx-0.8.15-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dwave-optimization==0.3.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_optimization-0.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (17 kB)\n",
      "Collecting dwave-preprocessing==0.6.6 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_preprocessing-0.6.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dwave-samplers==1.3.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_samplers-1.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.8 kB)\n",
      "Collecting dwave-system==1.26.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_system-1.26.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dwave-tabu==0.5.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwave_tabu-0.5.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting dwavebinarycsp==0.3.0 (from dwave-ocean-sdk)\n",
      "  Downloading dwavebinarycsp-0.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting minorminer==0.2.15 (from dwave-ocean-sdk)\n",
      "  Downloading minorminer-0.2.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting penaltymodel==1.1.0 (from dwave-ocean-sdk)\n",
      "  Downloading penaltymodel-1.1.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dimod==0.12.17->dwave-ocean-sdk) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2.25 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from requests[socks]<3,>=2.25->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (1.26.20)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.7.0)\n",
      "Collecting homebase<2,>=1.0 (from dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading homebase-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (8.1.7)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.9.0.post0)\n",
      "Collecting plucky<0.5,>=0.4.3 (from dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading plucky-0.4.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting diskcache<6,>=5.2.1 (from dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging>=19 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (24.1)\n",
      "Requirement already satisfied: werkzeug<4,>=2.2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5.0 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (4.11.0)\n",
      "Collecting authlib<2,>=1.2 (from dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading Authlib-1.3.2-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: importlib-metadata>=5.0.0 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (7.1.0)\n",
      "Requirement already satisfied: orjson>=3.10 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-cloud-client==0.13.1->dwave-ocean-sdk) (3.10.1)\n",
      "Requirement already satisfied: networkx in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-hybrid==0.6.12->dwave-ocean-sdk) (3.3)\n",
      "Requirement already satisfied: Flask<4,>=2.2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-inspector==0.5.1->dwave-ocean-sdk) (3.0.3)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from dwave-system==1.26.0->dwave-ocean-sdk) (1.13.0)\n",
      "Requirement already satisfied: fasteners>=0.15 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from minorminer==0.2.15->dwave-ocean-sdk) (0.19)\n",
      "Collecting cryptography (from authlib<2,>=1.2->dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from Flask<4,>=2.2->dwave-inspector==0.5.1->dwave-ocean-sdk) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from Flask<4,>=2.2->dwave-inspector==0.5.1->dwave-ocean-sdk) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from Flask<4,>=2.2->dwave-inspector==0.5.1->dwave-ocean-sdk) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from importlib-metadata>=5.0.0->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (3.18.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from pydantic<3,>=2->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from pydantic<3,>=2->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from python-dateutil<3,>=2.7->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from requests<3,>=2.25->requests[socks]<3,>=2.25->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from requests<3,>=2.25->requests[socks]<3,>=2.25->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from requests<3,>=2.25->requests[socks]<3,>=2.25->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2024.2.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3,>=2.25->dwave-cloud-client==0.13.1->dwave-ocean-sdk)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from werkzeug<4,>=2.2->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.1.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from cryptography->authlib<2,>=1.2->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/liljaco/Desktop/Github/venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography->authlib<2,>=1.2->dwave-cloud-client==0.13.1->dwave-ocean-sdk) (2.22)\n",
      "Downloading dwave_ocean_sdk-8.0.1-py3-none-any.whl (8.4 kB)\n",
      "Downloading dimod-0.12.17-cp312-cp312-macosx_11_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dwave_cloud_client-0.13.1-py3-none-any.whl (158 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.9/158.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_gate-0.3.2-cp312-cp312-macosx_11_0_arm64.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.1/605.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_greedy-0.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading dwave_hybrid-0.6.12-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_inspector-0.5.1-py3-none-any.whl (31 kB)\n",
      "Downloading dwave_neal-0.6.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading dwave_networkx-0.8.15-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_optimization-0.3.0-cp312-cp312-macosx_11_0_arm64.whl (893 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m893.4/893.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_preprocessing-0.6.6-cp312-cp312-macosx_11_0_arm64.whl (702 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.7/702.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_samplers-1.3.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dwave_system-1.26.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dwave_tabu-0.5.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading dwavebinarycsp-0.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading minorminer-0.2.15-cp312-cp312-macosx_11_0_arm64.whl (952 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.9/952.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading penaltymodel-1.1.0-py3-none-any.whl (36 kB)\n",
      "Downloading Authlib-1.3.2-py2.py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading homebase-1.0.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading plucky-0.4.3-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: plucky, homebase, PySocks, dwave-optimization, dwave-gate, diskcache, dimod, penaltymodel, dwave-samplers, dwave-preprocessing, dwave-networkx, cryptography, minorminer, dwavebinarycsp, dwave-tabu, dwave-neal, dwave-greedy, authlib, dwave-cloud-client, dwave-system, dwave-inspector, dwave-hybrid, dwave-ocean-sdk\n",
      "Successfully installed PySocks-1.7.1 authlib-1.3.2 cryptography-43.0.3 dimod-0.12.17 diskcache-5.6.3 dwave-cloud-client-0.13.1 dwave-gate-0.3.2 dwave-greedy-0.3.0 dwave-hybrid-0.6.12 dwave-inspector-0.5.1 dwave-neal-0.6.0 dwave-networkx-0.8.15 dwave-ocean-sdk-8.0.1 dwave-optimization-0.3.0 dwave-preprocessing-0.6.6 dwave-samplers-1.3.0 dwave-system-1.26.0 dwave-tabu-0.5.0 dwavebinarycsp-0.3.0 homebase-1.0.1 minorminer-0.2.15 penaltymodel-1.1.0 plucky-0.4.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dwave-ocean-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "\n",
    "from dimod import BQM\n",
    "from qiskit_optimization.problems import QuadraticProgram\n",
    "from qiskit_optimization.converters import QuadraticProgramToQubo\n",
    "from dimod.reference.samplers import ExactSolver\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('DWA_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. From Integer Linear Programming (ILP) to Quadratic Unconstrained Binary Optimization (QUBO)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define the ILP formulation of the BPP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BPP_ILP_Program(object_sizes, container_capacity):\n",
    "    num_objects = len(object_sizes)  # Number of objects\n",
    "    max_containers = num_objects  # Maximum number of containers (can have up to num_objects containers)\n",
    "\n",
    "        # Create the quadratic program\n",
    "    qp = QuadraticProgram()\n",
    "\n",
    "    # Binary variables for containers\n",
    "    container_usage_variables = {}\n",
    "    for container in range(max_containers):\n",
    "        container_var = f\"y{container + 1}\"  # Variable to indicate if the container is in use\n",
    "        container_usage_variables[container_var] = 1  # Coefficient for minimization\n",
    "        qp.binary_var(container_var)\n",
    "    \n",
    "    # Objective function: minimize the number of containers used\n",
    "    qp.minimize(linear=container_usage_variables)\n",
    "\n",
    "        # Constraint 1: Each object must be assigned to exactly one container\n",
    "    for obj in range(num_objects):\n",
    "        object_assignment_vars = {}\n",
    "        for container in range(max_containers):\n",
    "            assignment_var = f\"x{obj+1}_{container+1}\"  # Variable for object assignment to containers\n",
    "            object_assignment_vars[assignment_var] = 1\n",
    "            qp.binary_var(assignment_var)\n",
    "        qp.linear_constraint(linear=object_assignment_vars, sense=\"==\", rhs=1, name=f\"x_{obj + 1}_assigned_const\")\n",
    "\n",
    "    # Constraint 2: The total size of objects in each container must not exceed its capacity\n",
    "    for container in range(max_containers):\n",
    "        container_load_vars = {}\n",
    "        for obj in range(num_objects):\n",
    "            assignment_var = f\"x{obj+1}_{container+1}\"\n",
    "            container_load_vars[assignment_var] = object_sizes[obj]  # Size of the object\n",
    "        \n",
    "        container_var = f\"y{container + 1}\"\n",
    "        container_load_vars[container_var] = -container_capacity  # Container capacity\n",
    "        qp.linear_constraint(linear=container_load_vars, sense=\"<=\", rhs=0, name=f\"y_{container+1}_capacity_const\")\n",
    "\n",
    "    return qp\n",
    "\n",
    "\n",
    "\n",
    "# Problem parameters\n",
    "object_sizes = [4, 8, 1, 4]  # Sizes of the objects\n",
    "container_capacity = 10  # Capacity of the containers\n",
    "\n",
    "qp = BPP_ILP_Program(object_sizes, container_capacity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create a function to transform the ILP model into a QUBO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem name: \n",
      "\n",
      "Minimize\n",
      "  85*x1_1^2 + 10*x1_1*x1_2 + 10*x1_1*x1_3 + 10*x1_1*x1_4 + 320*x1_1*x2_1\n",
      "  + 40*x1_1*x3_1 + 160*x1_1*x4_1 + 40*x1_1*y_1_capacity_const@int_slack@0\n",
      "  + 80*x1_1*y_1_capacity_const@int_slack@1\n",
      "  + 160*x1_1*y_1_capacity_const@int_slack@2\n",
      "  + 120*x1_1*y_1_capacity_const@int_slack@3 + 85*x1_2^2 + 10*x1_2*x1_3\n",
      "  + 10*x1_2*x1_4 + 320*x1_2*x2_2 + 40*x1_2*x3_2 + 160*x1_2*x4_2\n",
      "  + 40*x1_2*y_2_capacity_const@int_slack@0\n",
      "  + 80*x1_2*y_2_capacity_const@int_slack@1\n",
      "  + 160*x1_2*y_2_capacity_const@int_slack@2\n",
      "  + 120*x1_2*y_2_capacity_const@int_slack@3 + 85*x1_3^2 + 10*x1_3*x1_4\n",
      "  + 320*x1_3*x2_3 + 40*x1_3*x3_3 + 160*x1_3*x4_3\n",
      "  + 40*x1_3*y_3_capacity_const@int_slack@0\n",
      "  + 80*x1_3*y_3_capacity_const@int_slack@1\n",
      "  + 160*x1_3*y_3_capacity_const@int_slack@2\n",
      "  + 120*x1_3*y_3_capacity_const@int_slack@3 + 85*x1_4^2 + 320*x1_4*x2_4\n",
      "  + 40*x1_4*x3_4 + 160*x1_4*x4_4 + 40*x1_4*y_4_capacity_const@int_slack@0\n",
      "  + 80*x1_4*y_4_capacity_const@int_slack@1\n",
      "  + 160*x1_4*y_4_capacity_const@int_slack@2\n",
      "  + 120*x1_4*y_4_capacity_const@int_slack@3 + 325*x2_1^2 + 10*x2_1*x2_2\n",
      "  + 10*x2_1*x2_3 + 10*x2_1*x2_4 + 80*x2_1*x3_1 + 320*x2_1*x4_1\n",
      "  + 80*x2_1*y_1_capacity_const@int_slack@0\n",
      "  + 160*x2_1*y_1_capacity_const@int_slack@1\n",
      "  + 320*x2_1*y_1_capacity_const@int_slack@2\n",
      "  + 240*x2_1*y_1_capacity_const@int_slack@3 + 325*x2_2^2 + 10*x2_2*x2_3\n",
      "  + 10*x2_2*x2_4 + 80*x2_2*x3_2 + 320*x2_2*x4_2\n",
      "  + 80*x2_2*y_2_capacity_const@int_slack@0\n",
      "  + 160*x2_2*y_2_capacity_const@int_slack@1\n",
      "  + 320*x2_2*y_2_capacity_const@int_slack@2\n",
      "  + 240*x2_2*y_2_capacity_const@int_slack@3 + 325*x2_3^2 + 10*x2_3*x2_4\n",
      "  + 80*x2_3*x3_3 + 320*x2_3*x4_3 + 80*x2_3*y_3_capacity_const@int_slack@0\n",
      "  + 160*x2_3*y_3_capacity_const@int_slack@1\n",
      "  + 320*x2_3*y_3_capacity_const@int_slack@2\n",
      "  + 240*x2_3*y_3_capacity_const@int_slack@3 + 325*x2_4^2 + 80*x2_4*x3_4\n",
      "  + 320*x2_4*x4_4 + 80*x2_4*y_4_capacity_const@int_slack@0\n",
      "  + 160*x2_4*y_4_capacity_const@int_slack@1\n",
      "  + 320*x2_4*y_4_capacity_const@int_slack@2\n",
      "  + 240*x2_4*y_4_capacity_const@int_slack@3 + 10*x3_1^2 + 10*x3_1*x3_2\n",
      "  + 10*x3_1*x3_3 + 10*x3_1*x3_4 + 40*x3_1*x4_1\n",
      "  + 10*x3_1*y_1_capacity_const@int_slack@0\n",
      "  + 20*x3_1*y_1_capacity_const@int_slack@1\n",
      "  + 40*x3_1*y_1_capacity_const@int_slack@2\n",
      "  + 30*x3_1*y_1_capacity_const@int_slack@3 + 10*x3_2^2 + 10*x3_2*x3_3\n",
      "  + 10*x3_2*x3_4 + 40*x3_2*x4_2 + 10*x3_2*y_2_capacity_const@int_slack@0\n",
      "  + 20*x3_2*y_2_capacity_const@int_slack@1\n",
      "  + 40*x3_2*y_2_capacity_const@int_slack@2\n",
      "  + 30*x3_2*y_2_capacity_const@int_slack@3 + 10*x3_3^2 + 10*x3_3*x3_4\n",
      "  + 40*x3_3*x4_3 + 10*x3_3*y_3_capacity_const@int_slack@0\n",
      "  + 20*x3_3*y_3_capacity_const@int_slack@1\n",
      "  + 40*x3_3*y_3_capacity_const@int_slack@2\n",
      "  + 30*x3_3*y_3_capacity_const@int_slack@3 + 10*x3_4^2 + 40*x3_4*x4_4\n",
      "  + 10*x3_4*y_4_capacity_const@int_slack@0\n",
      "  + 20*x3_4*y_4_capacity_const@int_slack@1\n",
      "  + 40*x3_4*y_4_capacity_const@int_slack@2\n",
      "  + 30*x3_4*y_4_capacity_const@int_slack@3 + 85*x4_1^2 + 10*x4_1*x4_2\n",
      "  + 10*x4_1*x4_3 + 10*x4_1*x4_4 + 40*x4_1*y_1_capacity_const@int_slack@0\n",
      "  + 80*x4_1*y_1_capacity_const@int_slack@1\n",
      "  + 160*x4_1*y_1_capacity_const@int_slack@2\n",
      "  + 120*x4_1*y_1_capacity_const@int_slack@3 + 85*x4_2^2 + 10*x4_2*x4_3\n",
      "  + 10*x4_2*x4_4 + 40*x4_2*y_2_capacity_const@int_slack@0\n",
      "  + 80*x4_2*y_2_capacity_const@int_slack@1\n",
      "  + 160*x4_2*y_2_capacity_const@int_slack@2\n",
      "  + 120*x4_2*y_2_capacity_const@int_slack@3 + 85*x4_3^2 + 10*x4_3*x4_4\n",
      "  + 40*x4_3*y_3_capacity_const@int_slack@0\n",
      "  + 80*x4_3*y_3_capacity_const@int_slack@1\n",
      "  + 160*x4_3*y_3_capacity_const@int_slack@2\n",
      "  + 120*x4_3*y_3_capacity_const@int_slack@3 + 85*x4_4^2\n",
      "  + 40*x4_4*y_4_capacity_const@int_slack@0\n",
      "  + 80*x4_4*y_4_capacity_const@int_slack@1\n",
      "  + 160*x4_4*y_4_capacity_const@int_slack@2\n",
      "  + 120*x4_4*y_4_capacity_const@int_slack@3 - 400*y1*x1_1 - 800*y1*x2_1\n",
      "  - 100*y1*x3_1 - 400*y1*x4_1 + 500*y1^2 - 100*y1*y_1_capacity_const@int_slack@0\n",
      "  - 200*y1*y_1_capacity_const@int_slack@1\n",
      "  - 400*y1*y_1_capacity_const@int_slack@2\n",
      "  - 300*y1*y_1_capacity_const@int_slack@3 - 400*y2*x1_2 - 800*y2*x2_2\n",
      "  - 100*y2*x3_2 - 400*y2*x4_2 + 500*y2^2 - 100*y2*y_2_capacity_const@int_slack@0\n",
      "  - 200*y2*y_2_capacity_const@int_slack@1\n",
      "  - 400*y2*y_2_capacity_const@int_slack@2\n",
      "  - 300*y2*y_2_capacity_const@int_slack@3 - 400*y3*x1_3 - 800*y3*x2_3\n",
      "  - 100*y3*x3_3 - 400*y3*x4_3 + 500*y3^2 - 100*y3*y_3_capacity_const@int_slack@0\n",
      "  - 200*y3*y_3_capacity_const@int_slack@1\n",
      "  - 400*y3*y_3_capacity_const@int_slack@2\n",
      "  - 300*y3*y_3_capacity_const@int_slack@3 - 400*y4*x1_4 - 800*y4*x2_4\n",
      "  - 100*y4*x3_4 - 400*y4*x4_4 + 500*y4^2 - 100*y4*y_4_capacity_const@int_slack@0\n",
      "  - 200*y4*y_4_capacity_const@int_slack@1\n",
      "  - 400*y4*y_4_capacity_const@int_slack@2\n",
      "  - 300*y4*y_4_capacity_const@int_slack@3 + 5*y_1_capacity_const@int_slack@0^2\n",
      "  + 20*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@1\n",
      "  + 40*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@2\n",
      "  + 30*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@3\n",
      "  + 20*y_1_capacity_const@int_slack@1^2\n",
      "  + 80*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@2\n",
      "  + 60*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@3\n",
      "  + 80*y_1_capacity_const@int_slack@2^2\n",
      "  + 120*y_1_capacity_const@int_slack@2*y_1_capacity_const@int_slack@3\n",
      "  + 45*y_1_capacity_const@int_slack@3^2 + 5*y_2_capacity_const@int_slack@0^2\n",
      "  + 20*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@1\n",
      "  + 40*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@2\n",
      "  + 30*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@3\n",
      "  + 20*y_2_capacity_const@int_slack@1^2\n",
      "  + 80*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@2\n",
      "  + 60*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@3\n",
      "  + 80*y_2_capacity_const@int_slack@2^2\n",
      "  + 120*y_2_capacity_const@int_slack@2*y_2_capacity_const@int_slack@3\n",
      "  + 45*y_2_capacity_const@int_slack@3^2 + 5*y_3_capacity_const@int_slack@0^2\n",
      "  + 20*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@1\n",
      "  + 40*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@2\n",
      "  + 30*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@3\n",
      "  + 20*y_3_capacity_const@int_slack@1^2\n",
      "  + 80*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@2\n",
      "  + 60*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@3\n",
      "  + 80*y_3_capacity_const@int_slack@2^2\n",
      "  + 120*y_3_capacity_const@int_slack@2*y_3_capacity_const@int_slack@3\n",
      "  + 45*y_3_capacity_const@int_slack@3^2 + 5*y_4_capacity_const@int_slack@0^2\n",
      "  + 20*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@1\n",
      "  + 40*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@2\n",
      "  + 30*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@3\n",
      "  + 20*y_4_capacity_const@int_slack@1^2\n",
      "  + 80*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@2\n",
      "  + 60*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@3\n",
      "  + 80*y_4_capacity_const@int_slack@2^2\n",
      "  + 120*y_4_capacity_const@int_slack@2*y_4_capacity_const@int_slack@3\n",
      "  + 45*y_4_capacity_const@int_slack@3^2 - 10*x1_1 - 10*x1_2 - 10*x1_3 - 10*x1_4\n",
      "  - 10*x2_1 - 10*x2_2 - 10*x2_3 - 10*x2_4 - 10*x3_1 - 10*x3_2 - 10*x3_3\n",
      "  - 10*x3_4 - 10*x4_1 - 10*x4_2 - 10*x4_3 - 10*x4_4 + y1 + y2 + y3 + y4 + 20\n",
      "\n",
      "Subject to\n",
      "  No constraints\n",
      "\n",
      "  Binary variables (36)\n",
      "    y1 y2 y3 y4 x1_1 x1_2 x1_3 x1_4 x2_1 x2_2 x2_3 x2_4 x3_1 x3_2 x3_3 x3_4 x4_1\n",
      "    x4_2 x4_3 x4_4 y_1_capacity_const@int_slack@0 y_1_capacity_const@int_slack@1\n",
      "    y_1_capacity_const@int_slack@2 y_1_capacity_const@int_slack@3\n",
      "    y_2_capacity_const@int_slack@0 y_2_capacity_const@int_slack@1\n",
      "    y_2_capacity_const@int_slack@2 y_2_capacity_const@int_slack@3\n",
      "    y_3_capacity_const@int_slack@0 y_3_capacity_const@int_slack@1\n",
      "    y_3_capacity_const@int_slack@2 y_3_capacity_const@int_slack@3\n",
      "    y_4_capacity_const@int_slack@0 y_4_capacity_const@int_slack@1\n",
      "    y_4_capacity_const@int_slack@2 y_4_capacity_const@int_slack@3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def quadratic_program_to_qubo(qp):\n",
    "    conv = QuadraticProgramToQubo()\n",
    "    qubo_problem = conv.convert(qp)\n",
    "    return qubo_problem\n",
    "\n",
    "qubo_problem = quadratic_program_to_qubo(qp)\n",
    "\n",
    "# Print the problem formulation\n",
    "print(qubo_problem.prettyprint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example BPP small**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILP VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  y1 + y2 + y3\n",
      "\n",
      "Subject to\n",
      "  Linear constraints (6)\n",
      "    x1_1 + x1_2 + x1_3 == 1  'x_1_assigned_const'\n",
      "    x2_1 + x2_2 + x2_3 == 1  'x_2_assigned_const'\n",
      "    x3_1 + x3_2 + x3_3 == 1  'x_3_assigned_const'\n",
      "    3*x1_1 + 2*x2_1 + 5*x3_1 - 6*y1 <= 0  'y_1_capacity_const'\n",
      "    3*x1_2 + 2*x2_2 + 5*x3_2 - 6*y2 <= 0  'y_2_capacity_const'\n",
      "    3*x1_3 + 2*x2_3 + 5*x3_3 - 6*y3 <= 0  'y_3_capacity_const'\n",
      "\n",
      "  Binary variables (12)\n",
      "    y1 y2 y3 x1_1 x1_2 x1_3 x2_1 x2_2 x2_3 x3_1 x3_2 x3_3\n",
      "\n",
      "QUBO VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  85*x1_1^2 + 10*x1_1*x1_2 + 10*x1_1*x1_3 + 10*x1_1*x1_4 + 320*x1_1*x2_1\n",
      "  + 40*x1_1*x3_1 + 160*x1_1*x4_1 + 40*x1_1*y_1_capacity_const@int_slack@0\n",
      "  + 80*x1_1*y_1_capacity_const@int_slack@1\n",
      "  + 160*x1_1*y_1_capacity_const@int_slack@2\n",
      "  + 120*x1_1*y_1_capacity_const@int_slack@3 + 85*x1_2^2 + 10*x1_2*x1_3\n",
      "  + 10*x1_2*x1_4 + 320*x1_2*x2_2 + 40*x1_2*x3_2 + 160*x1_2*x4_2\n",
      "  + 40*x1_2*y_2_capacity_const@int_slack@0\n",
      "  + 80*x1_2*y_2_capacity_const@int_slack@1\n",
      "  + 160*x1_2*y_2_capacity_const@int_slack@2\n",
      "  + 120*x1_2*y_2_capacity_const@int_slack@3 + 85*x1_3^2 + 10*x1_3*x1_4\n",
      "  + 320*x1_3*x2_3 + 40*x1_3*x3_3 + 160*x1_3*x4_3\n",
      "  + 40*x1_3*y_3_capacity_const@int_slack@0\n",
      "  + 80*x1_3*y_3_capacity_const@int_slack@1\n",
      "  + 160*x1_3*y_3_capacity_const@int_slack@2\n",
      "  + 120*x1_3*y_3_capacity_const@int_slack@3 + 85*x1_4^2 + 320*x1_4*x2_4\n",
      "  + 40*x1_4*x3_4 + 160*x1_4*x4_4 + 40*x1_4*y_4_capacity_const@int_slack@0\n",
      "  + 80*x1_4*y_4_capacity_const@int_slack@1\n",
      "  + 160*x1_4*y_4_capacity_const@int_slack@2\n",
      "  + 120*x1_4*y_4_capacity_const@int_slack@3 + 325*x2_1^2 + 10*x2_1*x2_2\n",
      "  + 10*x2_1*x2_3 + 10*x2_1*x2_4 + 80*x2_1*x3_1 + 320*x2_1*x4_1\n",
      "  + 80*x2_1*y_1_capacity_const@int_slack@0\n",
      "  + 160*x2_1*y_1_capacity_const@int_slack@1\n",
      "  + 320*x2_1*y_1_capacity_const@int_slack@2\n",
      "  + 240*x2_1*y_1_capacity_const@int_slack@3 + 325*x2_2^2 + 10*x2_2*x2_3\n",
      "  + 10*x2_2*x2_4 + 80*x2_2*x3_2 + 320*x2_2*x4_2\n",
      "  + 80*x2_2*y_2_capacity_const@int_slack@0\n",
      "  + 160*x2_2*y_2_capacity_const@int_slack@1\n",
      "  + 320*x2_2*y_2_capacity_const@int_slack@2\n",
      "  + 240*x2_2*y_2_capacity_const@int_slack@3 + 325*x2_3^2 + 10*x2_3*x2_4\n",
      "  + 80*x2_3*x3_3 + 320*x2_3*x4_3 + 80*x2_3*y_3_capacity_const@int_slack@0\n",
      "  + 160*x2_3*y_3_capacity_const@int_slack@1\n",
      "  + 320*x2_3*y_3_capacity_const@int_slack@2\n",
      "  + 240*x2_3*y_3_capacity_const@int_slack@3 + 325*x2_4^2 + 80*x2_4*x3_4\n",
      "  + 320*x2_4*x4_4 + 80*x2_4*y_4_capacity_const@int_slack@0\n",
      "  + 160*x2_4*y_4_capacity_const@int_slack@1\n",
      "  + 320*x2_4*y_4_capacity_const@int_slack@2\n",
      "  + 240*x2_4*y_4_capacity_const@int_slack@3 + 10*x3_1^2 + 10*x3_1*x3_2\n",
      "  + 10*x3_1*x3_3 + 10*x3_1*x3_4 + 40*x3_1*x4_1\n",
      "  + 10*x3_1*y_1_capacity_const@int_slack@0\n",
      "  + 20*x3_1*y_1_capacity_const@int_slack@1\n",
      "  + 40*x3_1*y_1_capacity_const@int_slack@2\n",
      "  + 30*x3_1*y_1_capacity_const@int_slack@3 + 10*x3_2^2 + 10*x3_2*x3_3\n",
      "  + 10*x3_2*x3_4 + 40*x3_2*x4_2 + 10*x3_2*y_2_capacity_const@int_slack@0\n",
      "  + 20*x3_2*y_2_capacity_const@int_slack@1\n",
      "  + 40*x3_2*y_2_capacity_const@int_slack@2\n",
      "  + 30*x3_2*y_2_capacity_const@int_slack@3 + 10*x3_3^2 + 10*x3_3*x3_4\n",
      "  + 40*x3_3*x4_3 + 10*x3_3*y_3_capacity_const@int_slack@0\n",
      "  + 20*x3_3*y_3_capacity_const@int_slack@1\n",
      "  + 40*x3_3*y_3_capacity_const@int_slack@2\n",
      "  + 30*x3_3*y_3_capacity_const@int_slack@3 + 10*x3_4^2 + 40*x3_4*x4_4\n",
      "  + 10*x3_4*y_4_capacity_const@int_slack@0\n",
      "  + 20*x3_4*y_4_capacity_const@int_slack@1\n",
      "  + 40*x3_4*y_4_capacity_const@int_slack@2\n",
      "  + 30*x3_4*y_4_capacity_const@int_slack@3 + 85*x4_1^2 + 10*x4_1*x4_2\n",
      "  + 10*x4_1*x4_3 + 10*x4_1*x4_4 + 40*x4_1*y_1_capacity_const@int_slack@0\n",
      "  + 80*x4_1*y_1_capacity_const@int_slack@1\n",
      "  + 160*x4_1*y_1_capacity_const@int_slack@2\n",
      "  + 120*x4_1*y_1_capacity_const@int_slack@3 + 85*x4_2^2 + 10*x4_2*x4_3\n",
      "  + 10*x4_2*x4_4 + 40*x4_2*y_2_capacity_const@int_slack@0\n",
      "  + 80*x4_2*y_2_capacity_const@int_slack@1\n",
      "  + 160*x4_2*y_2_capacity_const@int_slack@2\n",
      "  + 120*x4_2*y_2_capacity_const@int_slack@3 + 85*x4_3^2 + 10*x4_3*x4_4\n",
      "  + 40*x4_3*y_3_capacity_const@int_slack@0\n",
      "  + 80*x4_3*y_3_capacity_const@int_slack@1\n",
      "  + 160*x4_3*y_3_capacity_const@int_slack@2\n",
      "  + 120*x4_3*y_3_capacity_const@int_slack@3 + 85*x4_4^2\n",
      "  + 40*x4_4*y_4_capacity_const@int_slack@0\n",
      "  + 80*x4_4*y_4_capacity_const@int_slack@1\n",
      "  + 160*x4_4*y_4_capacity_const@int_slack@2\n",
      "  + 120*x4_4*y_4_capacity_const@int_slack@3 - 400*y1*x1_1 - 800*y1*x2_1\n",
      "  - 100*y1*x3_1 - 400*y1*x4_1 + 500*y1^2 - 100*y1*y_1_capacity_const@int_slack@0\n",
      "  - 200*y1*y_1_capacity_const@int_slack@1\n",
      "  - 400*y1*y_1_capacity_const@int_slack@2\n",
      "  - 300*y1*y_1_capacity_const@int_slack@3 - 400*y2*x1_2 - 800*y2*x2_2\n",
      "  - 100*y2*x3_2 - 400*y2*x4_2 + 500*y2^2 - 100*y2*y_2_capacity_const@int_slack@0\n",
      "  - 200*y2*y_2_capacity_const@int_slack@1\n",
      "  - 400*y2*y_2_capacity_const@int_slack@2\n",
      "  - 300*y2*y_2_capacity_const@int_slack@3 - 400*y3*x1_3 - 800*y3*x2_3\n",
      "  - 100*y3*x3_3 - 400*y3*x4_3 + 500*y3^2 - 100*y3*y_3_capacity_const@int_slack@0\n",
      "  - 200*y3*y_3_capacity_const@int_slack@1\n",
      "  - 400*y3*y_3_capacity_const@int_slack@2\n",
      "  - 300*y3*y_3_capacity_const@int_slack@3 - 400*y4*x1_4 - 800*y4*x2_4\n",
      "  - 100*y4*x3_4 - 400*y4*x4_4 + 500*y4^2 - 100*y4*y_4_capacity_const@int_slack@0\n",
      "  - 200*y4*y_4_capacity_const@int_slack@1\n",
      "  - 400*y4*y_4_capacity_const@int_slack@2\n",
      "  - 300*y4*y_4_capacity_const@int_slack@3 + 5*y_1_capacity_const@int_slack@0^2\n",
      "  + 20*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@1\n",
      "  + 40*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@2\n",
      "  + 30*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@3\n",
      "  + 20*y_1_capacity_const@int_slack@1^2\n",
      "  + 80*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@2\n",
      "  + 60*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@3\n",
      "  + 80*y_1_capacity_const@int_slack@2^2\n",
      "  + 120*y_1_capacity_const@int_slack@2*y_1_capacity_const@int_slack@3\n",
      "  + 45*y_1_capacity_const@int_slack@3^2 + 5*y_2_capacity_const@int_slack@0^2\n",
      "  + 20*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@1\n",
      "  + 40*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@2\n",
      "  + 30*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@3\n",
      "  + 20*y_2_capacity_const@int_slack@1^2\n",
      "  + 80*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@2\n",
      "  + 60*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@3\n",
      "  + 80*y_2_capacity_const@int_slack@2^2\n",
      "  + 120*y_2_capacity_const@int_slack@2*y_2_capacity_const@int_slack@3\n",
      "  + 45*y_2_capacity_const@int_slack@3^2 + 5*y_3_capacity_const@int_slack@0^2\n",
      "  + 20*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@1\n",
      "  + 40*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@2\n",
      "  + 30*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@3\n",
      "  + 20*y_3_capacity_const@int_slack@1^2\n",
      "  + 80*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@2\n",
      "  + 60*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@3\n",
      "  + 80*y_3_capacity_const@int_slack@2^2\n",
      "  + 120*y_3_capacity_const@int_slack@2*y_3_capacity_const@int_slack@3\n",
      "  + 45*y_3_capacity_const@int_slack@3^2 + 5*y_4_capacity_const@int_slack@0^2\n",
      "  + 20*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@1\n",
      "  + 40*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@2\n",
      "  + 30*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@3\n",
      "  + 20*y_4_capacity_const@int_slack@1^2\n",
      "  + 80*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@2\n",
      "  + 60*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@3\n",
      "  + 80*y_4_capacity_const@int_slack@2^2\n",
      "  + 120*y_4_capacity_const@int_slack@2*y_4_capacity_const@int_slack@3\n",
      "  + 45*y_4_capacity_const@int_slack@3^2 - 10*x1_1 - 10*x1_2 - 10*x1_3 - 10*x1_4\n",
      "  - 10*x2_1 - 10*x2_2 - 10*x2_3 - 10*x2_4 - 10*x3_1 - 10*x3_2 - 10*x3_3\n",
      "  - 10*x3_4 - 10*x4_1 - 10*x4_2 - 10*x4_3 - 10*x4_4 + y1 + y2 + y3 + y4 + 20\n",
      "\n",
      "Subject to\n",
      "  No constraints\n",
      "\n",
      "  Binary variables (36)\n",
      "    y1 y2 y3 y4 x1_1 x1_2 x1_3 x1_4 x2_1 x2_2 x2_3 x2_4 x3_1 x3_2 x3_3 x3_4 x4_1\n",
      "    x4_2 x4_3 x4_4 y_1_capacity_const@int_slack@0 y_1_capacity_const@int_slack@1\n",
      "    y_1_capacity_const@int_slack@2 y_1_capacity_const@int_slack@3\n",
      "    y_2_capacity_const@int_slack@0 y_2_capacity_const@int_slack@1\n",
      "    y_2_capacity_const@int_slack@2 y_2_capacity_const@int_slack@3\n",
      "    y_3_capacity_const@int_slack@0 y_3_capacity_const@int_slack@1\n",
      "    y_3_capacity_const@int_slack@2 y_3_capacity_const@int_slack@3\n",
      "    y_4_capacity_const@int_slack@0 y_4_capacity_const@int_slack@1\n",
      "    y_4_capacity_const@int_slack@2 y_4_capacity_const@int_slack@3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sizes = [3, 2, 5]\n",
    "bin_capacity = 6\n",
    "model_ilp_small = BPP_ILP_Program(sizes, bin_capacity)\n",
    "print(\"ILP VERSION\",model_ilp_small.prettyprint())\n",
    "\n",
    "qubo_problem_large = quadratic_program_to_qubo(model_ilp_small)\n",
    "\n",
    "print(\"QUBO VERSION\",qubo_problem.prettyprint())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example BPP medium**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILP VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  y1 + y2 + y3 + y4 + y5 + y6\n",
      "\n",
      "Subject to\n",
      "  Linear constraints (12)\n",
      "    x1_1 + x1_2 + x1_3 + x1_4 + x1_5 + x1_6 == 1  'x_1_assigned_const'\n",
      "    x2_1 + x2_2 + x2_3 + x2_4 + x2_5 + x2_6 == 1  'x_2_assigned_const'\n",
      "    x3_1 + x3_2 + x3_3 + x3_4 + x3_5 + x3_6 == 1  'x_3_assigned_const'\n",
      "    x4_1 + x4_2 + x4_3 + x4_4 + x4_5 + x4_6 == 1  'x_4_assigned_const'\n",
      "    x5_1 + x5_2 + x5_3 + x5_4 + x5_5 + x5_6 == 1  'x_5_assigned_const'\n",
      "    x6_1 + x6_2 + x6_3 + x6_4 + x6_5 + x6_6 == 1  'x_6_assigned_const'\n",
      "    3*x1_1 + 2*x2_1 + 5*x3_1 + 4*x4_1 + 7*x5_1 + 6*x6_1 - 10*y1\n",
      "    <= 0  'y_1_capacity_const'\n",
      "    3*x1_2 + 2*x2_2 + 5*x3_2 + 4*x4_2 + 7*x5_2 + 6*x6_2 - 10*y2\n",
      "    <= 0  'y_2_capacity_const'\n",
      "    3*x1_3 + 2*x2_3 + 5*x3_3 + 4*x4_3 + 7*x5_3 + 6*x6_3 - 10*y3\n",
      "    <= 0  'y_3_capacity_const'\n",
      "    3*x1_4 + 2*x2_4 + 5*x3_4 + 4*x4_4 + 7*x5_4 + 6*x6_4 - 10*y4\n",
      "    <= 0  'y_4_capacity_const'\n",
      "    3*x1_5 + 2*x2_5 + 5*x3_5 + 4*x4_5 + 7*x5_5 + 6*x6_5 - 10*y5\n",
      "    <= 0  'y_5_capacity_const'\n",
      "    3*x1_6 + 2*x2_6 + 5*x3_6 + 4*x4_6 + 7*x5_6 + 6*x6_6 - 10*y6\n",
      "    <= 0  'y_6_capacity_const'\n",
      "\n",
      "  Binary variables (42)\n",
      "    y1 y2 y3 y4 y5 y6 x1_1 x1_2 x1_3 x1_4 x1_5 x1_6 x2_1 x2_2 x2_3 x2_4 x2_5\n",
      "    x2_6 x3_1 x3_2 x3_3 x3_4 x3_5 x3_6 x4_1 x4_2 x4_3 x4_4 x4_5 x4_6 x5_1 x5_2\n",
      "    x5_3 x5_4 x5_5 x5_6 x6_1 x6_2 x6_3 x6_4 x6_5 x6_6\n",
      "\n",
      "QUBO VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  70*x1_1^2 + 14*x1_1*x1_2 + 14*x1_1*x1_3 + 14*x1_1*x1_4 + 14*x1_1*x1_5\n",
      "  + 14*x1_1*x1_6 + 84*x1_1*x2_1 + 210*x1_1*x3_1 + 168*x1_1*x4_1 + 294*x1_1*x5_1\n",
      "  + 252*x1_1*x6_1 + 42*x1_1*y_1_capacity_const@int_slack@0\n",
      "  + 84*x1_1*y_1_capacity_const@int_slack@1\n",
      "  + 168*x1_1*y_1_capacity_const@int_slack@2\n",
      "  + 126*x1_1*y_1_capacity_const@int_slack@3 + 70*x1_2^2 + 14*x1_2*x1_3\n",
      "  + 14*x1_2*x1_4 + 14*x1_2*x1_5 + 14*x1_2*x1_6 + 84*x1_2*x2_2 + 210*x1_2*x3_2\n",
      "  + 168*x1_2*x4_2 + 294*x1_2*x5_2 + 252*x1_2*x6_2\n",
      "  + 42*x1_2*y_2_capacity_const@int_slack@0\n",
      "  + 84*x1_2*y_2_capacity_const@int_slack@1\n",
      "  + 168*x1_2*y_2_capacity_const@int_slack@2\n",
      "  + 126*x1_2*y_2_capacity_const@int_slack@3 + 70*x1_3^2 + 14*x1_3*x1_4\n",
      "  + 14*x1_3*x1_5 + 14*x1_3*x1_6 + 84*x1_3*x2_3 + 210*x1_3*x3_3 + 168*x1_3*x4_3\n",
      "  + 294*x1_3*x5_3 + 252*x1_3*x6_3 + 42*x1_3*y_3_capacity_const@int_slack@0\n",
      "  + 84*x1_3*y_3_capacity_const@int_slack@1\n",
      "  + 168*x1_3*y_3_capacity_const@int_slack@2\n",
      "  + 126*x1_3*y_3_capacity_const@int_slack@3 + 70*x1_4^2 + 14*x1_4*x1_5\n",
      "  + 14*x1_4*x1_6 + 84*x1_4*x2_4 + 210*x1_4*x3_4 + 168*x1_4*x4_4 + 294*x1_4*x5_4\n",
      "  + 252*x1_4*x6_4 + 42*x1_4*y_4_capacity_const@int_slack@0\n",
      "  + 84*x1_4*y_4_capacity_const@int_slack@1\n",
      "  + 168*x1_4*y_4_capacity_const@int_slack@2\n",
      "  + 126*x1_4*y_4_capacity_const@int_slack@3 + 70*x1_5^2 + 14*x1_5*x1_6\n",
      "  + 84*x1_5*x2_5 + 210*x1_5*x3_5 + 168*x1_5*x4_5 + 294*x1_5*x5_5 + 252*x1_5*x6_5\n",
      "  + 42*x1_5*y_5_capacity_const@int_slack@0\n",
      "  + 84*x1_5*y_5_capacity_const@int_slack@1\n",
      "  + 168*x1_5*y_5_capacity_const@int_slack@2\n",
      "  + 126*x1_5*y_5_capacity_const@int_slack@3 + 70*x1_6^2 + 84*x1_6*x2_6\n",
      "  + 210*x1_6*x3_6 + 168*x1_6*x4_6 + 294*x1_6*x5_6 + 252*x1_6*x6_6\n",
      "  + 42*x1_6*y_6_capacity_const@int_slack@0\n",
      "  + 84*x1_6*y_6_capacity_const@int_slack@1\n",
      "  + 168*x1_6*y_6_capacity_const@int_slack@2\n",
      "  + 126*x1_6*y_6_capacity_const@int_slack@3 + 35*x2_1^2 + 14*x2_1*x2_2\n",
      "  + 14*x2_1*x2_3 + 14*x2_1*x2_4 + 14*x2_1*x2_5 + 14*x2_1*x2_6 + 140*x2_1*x3_1\n",
      "  + 112*x2_1*x4_1 + 196*x2_1*x5_1 + 168*x2_1*x6_1\n",
      "  + 28*x2_1*y_1_capacity_const@int_slack@0\n",
      "  + 56*x2_1*y_1_capacity_const@int_slack@1\n",
      "  + 112*x2_1*y_1_capacity_const@int_slack@2\n",
      "  + 84*x2_1*y_1_capacity_const@int_slack@3 + 35*x2_2^2 + 14*x2_2*x2_3\n",
      "  + 14*x2_2*x2_4 + 14*x2_2*x2_5 + 14*x2_2*x2_6 + 140*x2_2*x3_2 + 112*x2_2*x4_2\n",
      "  + 196*x2_2*x5_2 + 168*x2_2*x6_2 + 28*x2_2*y_2_capacity_const@int_slack@0\n",
      "  + 56*x2_2*y_2_capacity_const@int_slack@1\n",
      "  + 112*x2_2*y_2_capacity_const@int_slack@2\n",
      "  + 84*x2_2*y_2_capacity_const@int_slack@3 + 35*x2_3^2 + 14*x2_3*x2_4\n",
      "  + 14*x2_3*x2_5 + 14*x2_3*x2_6 + 140*x2_3*x3_3 + 112*x2_3*x4_3 + 196*x2_3*x5_3\n",
      "  + 168*x2_3*x6_3 + 28*x2_3*y_3_capacity_const@int_slack@0\n",
      "  + 56*x2_3*y_3_capacity_const@int_slack@1\n",
      "  + 112*x2_3*y_3_capacity_const@int_slack@2\n",
      "  + 84*x2_3*y_3_capacity_const@int_slack@3 + 35*x2_4^2 + 14*x2_4*x2_5\n",
      "  + 14*x2_4*x2_6 + 140*x2_4*x3_4 + 112*x2_4*x4_4 + 196*x2_4*x5_4 + 168*x2_4*x6_4\n",
      "  + 28*x2_4*y_4_capacity_const@int_slack@0\n",
      "  + 56*x2_4*y_4_capacity_const@int_slack@1\n",
      "  + 112*x2_4*y_4_capacity_const@int_slack@2\n",
      "  + 84*x2_4*y_4_capacity_const@int_slack@3 + 35*x2_5^2 + 14*x2_5*x2_6\n",
      "  + 140*x2_5*x3_5 + 112*x2_5*x4_5 + 196*x2_5*x5_5 + 168*x2_5*x6_5\n",
      "  + 28*x2_5*y_5_capacity_const@int_slack@0\n",
      "  + 56*x2_5*y_5_capacity_const@int_slack@1\n",
      "  + 112*x2_5*y_5_capacity_const@int_slack@2\n",
      "  + 84*x2_5*y_5_capacity_const@int_slack@3 + 35*x2_6^2 + 140*x2_6*x3_6\n",
      "  + 112*x2_6*x4_6 + 196*x2_6*x5_6 + 168*x2_6*x6_6\n",
      "  + 28*x2_6*y_6_capacity_const@int_slack@0\n",
      "  + 56*x2_6*y_6_capacity_const@int_slack@1\n",
      "  + 112*x2_6*y_6_capacity_const@int_slack@2\n",
      "  + 84*x2_6*y_6_capacity_const@int_slack@3 + 182*x3_1^2 + 14*x3_1*x3_2\n",
      "  + 14*x3_1*x3_3 + 14*x3_1*x3_4 + 14*x3_1*x3_5 + 14*x3_1*x3_6 + 280*x3_1*x4_1\n",
      "  + 490*x3_1*x5_1 + 420*x3_1*x6_1 + 70*x3_1*y_1_capacity_const@int_slack@0\n",
      "  + 140*x3_1*y_1_capacity_const@int_slack@1\n",
      "  + 280*x3_1*y_1_capacity_const@int_slack@2\n",
      "  + 210*x3_1*y_1_capacity_const@int_slack@3 + 182*x3_2^2 + 14*x3_2*x3_3\n",
      "  + 14*x3_2*x3_4 + 14*x3_2*x3_5 + 14*x3_2*x3_6 + 280*x3_2*x4_2 + 490*x3_2*x5_2\n",
      "  + 420*x3_2*x6_2 + 70*x3_2*y_2_capacity_const@int_slack@0\n",
      "  + 140*x3_2*y_2_capacity_const@int_slack@1\n",
      "  + 280*x3_2*y_2_capacity_const@int_slack@2\n",
      "  + 210*x3_2*y_2_capacity_const@int_slack@3 + 182*x3_3^2 + 14*x3_3*x3_4\n",
      "  + 14*x3_3*x3_5 + 14*x3_3*x3_6 + 280*x3_3*x4_3 + 490*x3_3*x5_3 + 420*x3_3*x6_3\n",
      "  + 70*x3_3*y_3_capacity_const@int_slack@0\n",
      "  + 140*x3_3*y_3_capacity_const@int_slack@1\n",
      "  + 280*x3_3*y_3_capacity_const@int_slack@2\n",
      "  + 210*x3_3*y_3_capacity_const@int_slack@3 + 182*x3_4^2 + 14*x3_4*x3_5\n",
      "  + 14*x3_4*x3_6 + 280*x3_4*x4_4 + 490*x3_4*x5_4 + 420*x3_4*x6_4\n",
      "  + 70*x3_4*y_4_capacity_const@int_slack@0\n",
      "  + 140*x3_4*y_4_capacity_const@int_slack@1\n",
      "  + 280*x3_4*y_4_capacity_const@int_slack@2\n",
      "  + 210*x3_4*y_4_capacity_const@int_slack@3 + 182*x3_5^2 + 14*x3_5*x3_6\n",
      "  + 280*x3_5*x4_5 + 490*x3_5*x5_5 + 420*x3_5*x6_5\n",
      "  + 70*x3_5*y_5_capacity_const@int_slack@0\n",
      "  + 140*x3_5*y_5_capacity_const@int_slack@1\n",
      "  + 280*x3_5*y_5_capacity_const@int_slack@2\n",
      "  + 210*x3_5*y_5_capacity_const@int_slack@3 + 182*x3_6^2 + 280*x3_6*x4_6\n",
      "  + 490*x3_6*x5_6 + 420*x3_6*x6_6 + 70*x3_6*y_6_capacity_const@int_slack@0\n",
      "  + 140*x3_6*y_6_capacity_const@int_slack@1\n",
      "  + 280*x3_6*y_6_capacity_const@int_slack@2\n",
      "  + 210*x3_6*y_6_capacity_const@int_slack@3 + 119*x4_1^2 + 14*x4_1*x4_2\n",
      "  + 14*x4_1*x4_3 + 14*x4_1*x4_4 + 14*x4_1*x4_5 + 14*x4_1*x4_6 + 392*x4_1*x5_1\n",
      "  + 336*x4_1*x6_1 + 56*x4_1*y_1_capacity_const@int_slack@0\n",
      "  + 112*x4_1*y_1_capacity_const@int_slack@1\n",
      "  + 224*x4_1*y_1_capacity_const@int_slack@2\n",
      "  + 168*x4_1*y_1_capacity_const@int_slack@3 + 119*x4_2^2 + 14*x4_2*x4_3\n",
      "  + 14*x4_2*x4_4 + 14*x4_2*x4_5 + 14*x4_2*x4_6 + 392*x4_2*x5_2 + 336*x4_2*x6_2\n",
      "  + 56*x4_2*y_2_capacity_const@int_slack@0\n",
      "  + 112*x4_2*y_2_capacity_const@int_slack@1\n",
      "  + 224*x4_2*y_2_capacity_const@int_slack@2\n",
      "  + 168*x4_2*y_2_capacity_const@int_slack@3 + 119*x4_3^2 + 14*x4_3*x4_4\n",
      "  + 14*x4_3*x4_5 + 14*x4_3*x4_6 + 392*x4_3*x5_3 + 336*x4_3*x6_3\n",
      "  + 56*x4_3*y_3_capacity_const@int_slack@0\n",
      "  + 112*x4_3*y_3_capacity_const@int_slack@1\n",
      "  + 224*x4_3*y_3_capacity_const@int_slack@2\n",
      "  + 168*x4_3*y_3_capacity_const@int_slack@3 + 119*x4_4^2 + 14*x4_4*x4_5\n",
      "  + 14*x4_4*x4_6 + 392*x4_4*x5_4 + 336*x4_4*x6_4\n",
      "  + 56*x4_4*y_4_capacity_const@int_slack@0\n",
      "  + 112*x4_4*y_4_capacity_const@int_slack@1\n",
      "  + 224*x4_4*y_4_capacity_const@int_slack@2\n",
      "  + 168*x4_4*y_4_capacity_const@int_slack@3 + 119*x4_5^2 + 14*x4_5*x4_6\n",
      "  + 392*x4_5*x5_5 + 336*x4_5*x6_5 + 56*x4_5*y_5_capacity_const@int_slack@0\n",
      "  + 112*x4_5*y_5_capacity_const@int_slack@1\n",
      "  + 224*x4_5*y_5_capacity_const@int_slack@2\n",
      "  + 168*x4_5*y_5_capacity_const@int_slack@3 + 119*x4_6^2 + 392*x4_6*x5_6\n",
      "  + 336*x4_6*x6_6 + 56*x4_6*y_6_capacity_const@int_slack@0\n",
      "  + 112*x4_6*y_6_capacity_const@int_slack@1\n",
      "  + 224*x4_6*y_6_capacity_const@int_slack@2\n",
      "  + 168*x4_6*y_6_capacity_const@int_slack@3 + 350*x5_1^2 + 14*x5_1*x5_2\n",
      "  + 14*x5_1*x5_3 + 14*x5_1*x5_4 + 14*x5_1*x5_5 + 14*x5_1*x5_6 + 588*x5_1*x6_1\n",
      "  + 98*x5_1*y_1_capacity_const@int_slack@0\n",
      "  + 196*x5_1*y_1_capacity_const@int_slack@1\n",
      "  + 392*x5_1*y_1_capacity_const@int_slack@2\n",
      "  + 294*x5_1*y_1_capacity_const@int_slack@3 + 350*x5_2^2 + 14*x5_2*x5_3\n",
      "  + 14*x5_2*x5_4 + 14*x5_2*x5_5 + 14*x5_2*x5_6 + 588*x5_2*x6_2\n",
      "  + 98*x5_2*y_2_capacity_const@int_slack@0\n",
      "  + 196*x5_2*y_2_capacity_const@int_slack@1\n",
      "  + 392*x5_2*y_2_capacity_const@int_slack@2\n",
      "  + 294*x5_2*y_2_capacity_const@int_slack@3 + 350*x5_3^2 + 14*x5_3*x5_4\n",
      "  + 14*x5_3*x5_5 + 14*x5_3*x5_6 + 588*x5_3*x6_3\n",
      "  + 98*x5_3*y_3_capacity_const@int_slack@0\n",
      "  + 196*x5_3*y_3_capacity_const@int_slack@1\n",
      "  + 392*x5_3*y_3_capacity_const@int_slack@2\n",
      "  + 294*x5_3*y_3_capacity_const@int_slack@3 + 350*x5_4^2 + 14*x5_4*x5_5\n",
      "  + 14*x5_4*x5_6 + 588*x5_4*x6_4 + 98*x5_4*y_4_capacity_const@int_slack@0\n",
      "  + 196*x5_4*y_4_capacity_const@int_slack@1\n",
      "  + 392*x5_4*y_4_capacity_const@int_slack@2\n",
      "  + 294*x5_4*y_4_capacity_const@int_slack@3 + 350*x5_5^2 + 14*x5_5*x5_6\n",
      "  + 588*x5_5*x6_5 + 98*x5_5*y_5_capacity_const@int_slack@0\n",
      "  + 196*x5_5*y_5_capacity_const@int_slack@1\n",
      "  + 392*x5_5*y_5_capacity_const@int_slack@2\n",
      "  + 294*x5_5*y_5_capacity_const@int_slack@3 + 350*x5_6^2 + 588*x5_6*x6_6\n",
      "  + 98*x5_6*y_6_capacity_const@int_slack@0\n",
      "  + 196*x5_6*y_6_capacity_const@int_slack@1\n",
      "  + 392*x5_6*y_6_capacity_const@int_slack@2\n",
      "  + 294*x5_6*y_6_capacity_const@int_slack@3 + 259*x6_1^2 + 14*x6_1*x6_2\n",
      "  + 14*x6_1*x6_3 + 14*x6_1*x6_4 + 14*x6_1*x6_5 + 14*x6_1*x6_6\n",
      "  + 84*x6_1*y_1_capacity_const@int_slack@0\n",
      "  + 168*x6_1*y_1_capacity_const@int_slack@1\n",
      "  + 336*x6_1*y_1_capacity_const@int_slack@2\n",
      "  + 252*x6_1*y_1_capacity_const@int_slack@3 + 259*x6_2^2 + 14*x6_2*x6_3\n",
      "  + 14*x6_2*x6_4 + 14*x6_2*x6_5 + 14*x6_2*x6_6\n",
      "  + 84*x6_2*y_2_capacity_const@int_slack@0\n",
      "  + 168*x6_2*y_2_capacity_const@int_slack@1\n",
      "  + 336*x6_2*y_2_capacity_const@int_slack@2\n",
      "  + 252*x6_2*y_2_capacity_const@int_slack@3 + 259*x6_3^2 + 14*x6_3*x6_4\n",
      "  + 14*x6_3*x6_5 + 14*x6_3*x6_6 + 84*x6_3*y_3_capacity_const@int_slack@0\n",
      "  + 168*x6_3*y_3_capacity_const@int_slack@1\n",
      "  + 336*x6_3*y_3_capacity_const@int_slack@2\n",
      "  + 252*x6_3*y_3_capacity_const@int_slack@3 + 259*x6_4^2 + 14*x6_4*x6_5\n",
      "  + 14*x6_4*x6_6 + 84*x6_4*y_4_capacity_const@int_slack@0\n",
      "  + 168*x6_4*y_4_capacity_const@int_slack@1\n",
      "  + 336*x6_4*y_4_capacity_const@int_slack@2\n",
      "  + 252*x6_4*y_4_capacity_const@int_slack@3 + 259*x6_5^2 + 14*x6_5*x6_6\n",
      "  + 84*x6_5*y_5_capacity_const@int_slack@0\n",
      "  + 168*x6_5*y_5_capacity_const@int_slack@1\n",
      "  + 336*x6_5*y_5_capacity_const@int_slack@2\n",
      "  + 252*x6_5*y_5_capacity_const@int_slack@3 + 259*x6_6^2\n",
      "  + 84*x6_6*y_6_capacity_const@int_slack@0\n",
      "  + 168*x6_6*y_6_capacity_const@int_slack@1\n",
      "  + 336*x6_6*y_6_capacity_const@int_slack@2\n",
      "  + 252*x6_6*y_6_capacity_const@int_slack@3 - 420*y1*x1_1 - 280*y1*x2_1\n",
      "  - 700*y1*x3_1 - 560*y1*x4_1 - 980*y1*x5_1 - 840*y1*x6_1 + 700*y1^2\n",
      "  - 140*y1*y_1_capacity_const@int_slack@0\n",
      "  - 280*y1*y_1_capacity_const@int_slack@1\n",
      "  - 560*y1*y_1_capacity_const@int_slack@2\n",
      "  - 420*y1*y_1_capacity_const@int_slack@3 - 420*y2*x1_2 - 280*y2*x2_2\n",
      "  - 700*y2*x3_2 - 560*y2*x4_2 - 980*y2*x5_2 - 840*y2*x6_2 + 700*y2^2\n",
      "  - 140*y2*y_2_capacity_const@int_slack@0\n",
      "  - 280*y2*y_2_capacity_const@int_slack@1\n",
      "  - 560*y2*y_2_capacity_const@int_slack@2\n",
      "  - 420*y2*y_2_capacity_const@int_slack@3 - 420*y3*x1_3 - 280*y3*x2_3\n",
      "  - 700*y3*x3_3 - 560*y3*x4_3 - 980*y3*x5_3 - 840*y3*x6_3 + 700*y3^2\n",
      "  - 140*y3*y_3_capacity_const@int_slack@0\n",
      "  - 280*y3*y_3_capacity_const@int_slack@1\n",
      "  - 560*y3*y_3_capacity_const@int_slack@2\n",
      "  - 420*y3*y_3_capacity_const@int_slack@3 - 420*y4*x1_4 - 280*y4*x2_4\n",
      "  - 700*y4*x3_4 - 560*y4*x4_4 - 980*y4*x5_4 - 840*y4*x6_4 + 700*y4^2\n",
      "  - 140*y4*y_4_capacity_const@int_slack@0\n",
      "  - 280*y4*y_4_capacity_const@int_slack@1\n",
      "  - 560*y4*y_4_capacity_const@int_slack@2\n",
      "  - 420*y4*y_4_capacity_const@int_slack@3 - 420*y5*x1_5 - 280*y5*x2_5\n",
      "  - 700*y5*x3_5 - 560*y5*x4_5 - 980*y5*x5_5 - 840*y5*x6_5 + 700*y5^2\n",
      "  - 140*y5*y_5_capacity_const@int_slack@0\n",
      "  - 280*y5*y_5_capacity_const@int_slack@1\n",
      "  - 560*y5*y_5_capacity_const@int_slack@2\n",
      "  - 420*y5*y_5_capacity_const@int_slack@3 - 420*y6*x1_6 - 280*y6*x2_6\n",
      "  - 700*y6*x3_6 - 560*y6*x4_6 - 980*y6*x5_6 - 840*y6*x6_6 + 700*y6^2\n",
      "  - 140*y6*y_6_capacity_const@int_slack@0\n",
      "  - 280*y6*y_6_capacity_const@int_slack@1\n",
      "  - 560*y6*y_6_capacity_const@int_slack@2\n",
      "  - 420*y6*y_6_capacity_const@int_slack@3 + 7*y_1_capacity_const@int_slack@0^2\n",
      "  + 28*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@1\n",
      "  + 56*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@2\n",
      "  + 42*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@3\n",
      "  + 28*y_1_capacity_const@int_slack@1^2\n",
      "  + 112*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@2\n",
      "  + 84*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@3\n",
      "  + 112*y_1_capacity_const@int_slack@2^2\n",
      "  + 168*y_1_capacity_const@int_slack@2*y_1_capacity_const@int_slack@3\n",
      "  + 63*y_1_capacity_const@int_slack@3^2 + 7*y_2_capacity_const@int_slack@0^2\n",
      "  + 28*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@1\n",
      "  + 56*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@2\n",
      "  + 42*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@3\n",
      "  + 28*y_2_capacity_const@int_slack@1^2\n",
      "  + 112*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@2\n",
      "  + 84*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@3\n",
      "  + 112*y_2_capacity_const@int_slack@2^2\n",
      "  + 168*y_2_capacity_const@int_slack@2*y_2_capacity_const@int_slack@3\n",
      "  + 63*y_2_capacity_const@int_slack@3^2 + 7*y_3_capacity_const@int_slack@0^2\n",
      "  + 28*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@1\n",
      "  + 56*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@2\n",
      "  + 42*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@3\n",
      "  + 28*y_3_capacity_const@int_slack@1^2\n",
      "  + 112*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@2\n",
      "  + 84*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@3\n",
      "  + 112*y_3_capacity_const@int_slack@2^2\n",
      "  + 168*y_3_capacity_const@int_slack@2*y_3_capacity_const@int_slack@3\n",
      "  + 63*y_3_capacity_const@int_slack@3^2 + 7*y_4_capacity_const@int_slack@0^2\n",
      "  + 28*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@1\n",
      "  + 56*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@2\n",
      "  + 42*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@3\n",
      "  + 28*y_4_capacity_const@int_slack@1^2\n",
      "  + 112*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@2\n",
      "  + 84*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@3\n",
      "  + 112*y_4_capacity_const@int_slack@2^2\n",
      "  + 168*y_4_capacity_const@int_slack@2*y_4_capacity_const@int_slack@3\n",
      "  + 63*y_4_capacity_const@int_slack@3^2 + 7*y_5_capacity_const@int_slack@0^2\n",
      "  + 28*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@1\n",
      "  + 56*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@2\n",
      "  + 42*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@3\n",
      "  + 28*y_5_capacity_const@int_slack@1^2\n",
      "  + 112*y_5_capacity_const@int_slack@1*y_5_capacity_const@int_slack@2\n",
      "  + 84*y_5_capacity_const@int_slack@1*y_5_capacity_const@int_slack@3\n",
      "  + 112*y_5_capacity_const@int_slack@2^2\n",
      "  + 168*y_5_capacity_const@int_slack@2*y_5_capacity_const@int_slack@3\n",
      "  + 63*y_5_capacity_const@int_slack@3^2 + 7*y_6_capacity_const@int_slack@0^2\n",
      "  + 28*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@1\n",
      "  + 56*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@2\n",
      "  + 42*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@3\n",
      "  + 28*y_6_capacity_const@int_slack@1^2\n",
      "  + 112*y_6_capacity_const@int_slack@1*y_6_capacity_const@int_slack@2\n",
      "  + 84*y_6_capacity_const@int_slack@1*y_6_capacity_const@int_slack@3\n",
      "  + 112*y_6_capacity_const@int_slack@2^2\n",
      "  + 168*y_6_capacity_const@int_slack@2*y_6_capacity_const@int_slack@3\n",
      "  + 63*y_6_capacity_const@int_slack@3^2 - 14*x1_1 - 14*x1_2 - 14*x1_3 - 14*x1_4\n",
      "  - 14*x1_5 - 14*x1_6 - 14*x2_1 - 14*x2_2 - 14*x2_3 - 14*x2_4 - 14*x2_5\n",
      "  - 14*x2_6 - 14*x3_1 - 14*x3_2 - 14*x3_3 - 14*x3_4 - 14*x3_5 - 14*x3_6\n",
      "  - 14*x4_1 - 14*x4_2 - 14*x4_3 - 14*x4_4 - 14*x4_5 - 14*x4_6 - 14*x5_1\n",
      "  - 14*x5_2 - 14*x5_3 - 14*x5_4 - 14*x5_5 - 14*x5_6 - 14*x6_1 - 14*x6_2\n",
      "  - 14*x6_3 - 14*x6_4 - 14*x6_5 - 14*x6_6 + y1 + y2 + y3 + y4 + y5 + y6 + 42\n",
      "\n",
      "Subject to\n",
      "  No constraints\n",
      "\n",
      "  Binary variables (66)\n",
      "    y1 y2 y3 y4 y5 y6 x1_1 x1_2 x1_3 x1_4 x1_5 x1_6 x2_1 x2_2 x2_3 x2_4 x2_5\n",
      "    x2_6 x3_1 x3_2 x3_3 x3_4 x3_5 x3_6 x4_1 x4_2 x4_3 x4_4 x4_5 x4_6 x5_1 x5_2\n",
      "    x5_3 x5_4 x5_5 x5_6 x6_1 x6_2 x6_3 x6_4 x6_5 x6_6\n",
      "    y_1_capacity_const@int_slack@0 y_1_capacity_const@int_slack@1\n",
      "    y_1_capacity_const@int_slack@2 y_1_capacity_const@int_slack@3\n",
      "    y_2_capacity_const@int_slack@0 y_2_capacity_const@int_slack@1\n",
      "    y_2_capacity_const@int_slack@2 y_2_capacity_const@int_slack@3\n",
      "    y_3_capacity_const@int_slack@0 y_3_capacity_const@int_slack@1\n",
      "    y_3_capacity_const@int_slack@2 y_3_capacity_const@int_slack@3\n",
      "    y_4_capacity_const@int_slack@0 y_4_capacity_const@int_slack@1\n",
      "    y_4_capacity_const@int_slack@2 y_4_capacity_const@int_slack@3\n",
      "    y_5_capacity_const@int_slack@0 y_5_capacity_const@int_slack@1\n",
      "    y_5_capacity_const@int_slack@2 y_5_capacity_const@int_slack@3\n",
      "    y_6_capacity_const@int_slack@0 y_6_capacity_const@int_slack@1\n",
      "    y_6_capacity_const@int_slack@2 y_6_capacity_const@int_slack@3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sizes = [3, 2, 5, 4, 7, 6]\n",
    "bin_capacity = 10\n",
    "\n",
    "model_ilp_medium = BPP_ILP_Program(sizes, bin_capacity)\n",
    "print(\"ILP VERSION\",model_ilp_medium.prettyprint())\n",
    "\n",
    "qubo_problem_medium = quadratic_program_to_qubo(model_ilp_medium)\n",
    "\n",
    "print(\"QUBO VERSION\",qubo_problem.prettyprint())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example BPP large**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILP VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  y1 + y10 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9\n",
      "\n",
      "Subject to\n",
      "  Linear constraints (20)\n",
      "    x1_1 + x1_10 + x1_2 + x1_3 + x1_4 + x1_5 + x1_6 + x1_7 + x1_8 + x1_9\n",
      "    == 1  'x_1_assigned_const'\n",
      "    x2_1 + x2_10 + x2_2 + x2_3 + x2_4 + x2_5 + x2_6 + x2_7 + x2_8 + x2_9\n",
      "    == 1  'x_2_assigned_const'\n",
      "    x3_1 + x3_10 + x3_2 + x3_3 + x3_4 + x3_5 + x3_6 + x3_7 + x3_8 + x3_9\n",
      "    == 1  'x_3_assigned_const'\n",
      "    x4_1 + x4_10 + x4_2 + x4_3 + x4_4 + x4_5 + x4_6 + x4_7 + x4_8 + x4_9\n",
      "    == 1  'x_4_assigned_const'\n",
      "    x5_1 + x5_10 + x5_2 + x5_3 + x5_4 + x5_5 + x5_6 + x5_7 + x5_8 + x5_9\n",
      "    == 1  'x_5_assigned_const'\n",
      "    x6_1 + x6_10 + x6_2 + x6_3 + x6_4 + x6_5 + x6_6 + x6_7 + x6_8 + x6_9\n",
      "    == 1  'x_6_assigned_const'\n",
      "    x7_1 + x7_10 + x7_2 + x7_3 + x7_4 + x7_5 + x7_6 + x7_7 + x7_8 + x7_9\n",
      "    == 1  'x_7_assigned_const'\n",
      "    x8_1 + x8_10 + x8_2 + x8_3 + x8_4 + x8_5 + x8_6 + x8_7 + x8_8 + x8_9\n",
      "    == 1  'x_8_assigned_const'\n",
      "    x9_1 + x9_10 + x9_2 + x9_3 + x9_4 + x9_5 + x9_6 + x9_7 + x9_8 + x9_9\n",
      "    == 1  'x_9_assigned_const'\n",
      "    x10_1 + x10_10 + x10_2 + x10_3 + x10_4 + x10_5 + x10_6 + x10_7 + x10_8\n",
      "    + x10_9 == 1  'x_10_assigned_const'\n",
      "    10*x10_1 + 3*x1_1 + 2*x2_1 + 5*x3_1 + 4*x4_1 + 7*x5_1 + 6*x6_1 + x7_1\n",
      "    + 8*x8_1 + 9*x9_1 - 15*y1 <= 0  'y_1_capacity_const'\n",
      "    10*x10_2 + 3*x1_2 + 2*x2_2 + 5*x3_2 + 4*x4_2 + 7*x5_2 + 6*x6_2 + x7_2\n",
      "    + 8*x8_2 + 9*x9_2 - 15*y2 <= 0  'y_2_capacity_const'\n",
      "    10*x10_3 + 3*x1_3 + 2*x2_3 + 5*x3_3 + 4*x4_3 + 7*x5_3 + 6*x6_3 + x7_3\n",
      "    + 8*x8_3 + 9*x9_3 - 15*y3 <= 0  'y_3_capacity_const'\n",
      "    10*x10_4 + 3*x1_4 + 2*x2_4 + 5*x3_4 + 4*x4_4 + 7*x5_4 + 6*x6_4 + x7_4\n",
      "    + 8*x8_4 + 9*x9_4 - 15*y4 <= 0  'y_4_capacity_const'\n",
      "    10*x10_5 + 3*x1_5 + 2*x2_5 + 5*x3_5 + 4*x4_5 + 7*x5_5 + 6*x6_5 + x7_5\n",
      "    + 8*x8_5 + 9*x9_5 - 15*y5 <= 0  'y_5_capacity_const'\n",
      "    10*x10_6 + 3*x1_6 + 2*x2_6 + 5*x3_6 + 4*x4_6 + 7*x5_6 + 6*x6_6 + x7_6\n",
      "    + 8*x8_6 + 9*x9_6 - 15*y6 <= 0  'y_6_capacity_const'\n",
      "    10*x10_7 + 3*x1_7 + 2*x2_7 + 5*x3_7 + 4*x4_7 + 7*x5_7 + 6*x6_7 + x7_7\n",
      "    + 8*x8_7 + 9*x9_7 - 15*y7 <= 0  'y_7_capacity_const'\n",
      "    10*x10_8 + 3*x1_8 + 2*x2_8 + 5*x3_8 + 4*x4_8 + 7*x5_8 + 6*x6_8 + x7_8\n",
      "    + 8*x8_8 + 9*x9_8 - 15*y8 <= 0  'y_8_capacity_const'\n",
      "    10*x10_9 + 3*x1_9 + 2*x2_9 + 5*x3_9 + 4*x4_9 + 7*x5_9 + 6*x6_9 + x7_9\n",
      "    + 8*x8_9 + 9*x9_9 - 15*y9 <= 0  'y_9_capacity_const'\n",
      "    10*x10_10 + 3*x1_10 + 2*x2_10 + 5*x3_10 + 4*x4_10 + 7*x5_10 + 6*x6_10\n",
      "    + x7_10 + 8*x8_10 + 9*x9_10 - 15*y10 <= 0  'y_10_capacity_const'\n",
      "\n",
      "  Binary variables (110)\n",
      "    y1 y2 y3 y4 y5 y6 y7 y8 y9 y10 x1_1 x1_2 x1_3 x1_4 x1_5 x1_6 x1_7 x1_8 x1_9\n",
      "    x1_10 x2_1 x2_2 x2_3 x2_4 x2_5 x2_6 x2_7 x2_8 x2_9 x2_10 x3_1 x3_2 x3_3 x3_4\n",
      "    x3_5 x3_6 x3_7 x3_8 x3_9 x3_10 x4_1 x4_2 x4_3 x4_4 x4_5 x4_6 x4_7 x4_8 x4_9\n",
      "    x4_10 x5_1 x5_2 x5_3 x5_4 x5_5 x5_6 x5_7 x5_8 x5_9 x5_10 x6_1 x6_2 x6_3 x6_4\n",
      "    x6_5 x6_6 x6_7 x6_8 x6_9 x6_10 x7_1 x7_2 x7_3 x7_4 x7_5 x7_6 x7_7 x7_8 x7_9\n",
      "    x7_10 x8_1 x8_2 x8_3 x8_4 x8_5 x8_6 x8_7 x8_8 x8_9 x8_10 x9_1 x9_2 x9_3 x9_4\n",
      "    x9_5 x9_6 x9_7 x9_8 x9_9 x9_10 x10_1 x10_2 x10_3 x10_4 x10_5 x10_6 x10_7\n",
      "    x10_8 x10_9 x10_10\n",
      "\n",
      "QUBO VERSION Problem name: \n",
      "\n",
      "Minimize\n",
      "  1111*x10_1^2 + 22*x10_1*x10_10 + 22*x10_1*x10_2 + 22*x10_1*x10_3\n",
      "  + 22*x10_1*x10_4 + 22*x10_1*x10_5 + 22*x10_1*x10_6 + 22*x10_1*x10_7\n",
      "  + 22*x10_1*x10_8 + 22*x10_1*x10_9 + 220*x10_1*y_1_capacity_const@int_slack@0\n",
      "  + 440*x10_1*y_1_capacity_const@int_slack@1\n",
      "  + 880*x10_1*y_1_capacity_const@int_slack@2\n",
      "  + 1760*x10_1*y_1_capacity_const@int_slack@3 + 1111*x10_10^2\n",
      "  + 220*x10_10*y_10_capacity_const@int_slack@0\n",
      "  + 440*x10_10*y_10_capacity_const@int_slack@1\n",
      "  + 880*x10_10*y_10_capacity_const@int_slack@2\n",
      "  + 1760*x10_10*y_10_capacity_const@int_slack@3 + 22*x10_2*x10_10 + 1111*x10_2^2\n",
      "  + 22*x10_2*x10_3 + 22*x10_2*x10_4 + 22*x10_2*x10_5 + 22*x10_2*x10_6\n",
      "  + 22*x10_2*x10_7 + 22*x10_2*x10_8 + 22*x10_2*x10_9\n",
      "  + 220*x10_2*y_2_capacity_const@int_slack@0\n",
      "  + 440*x10_2*y_2_capacity_const@int_slack@1\n",
      "  + 880*x10_2*y_2_capacity_const@int_slack@2\n",
      "  + 1760*x10_2*y_2_capacity_const@int_slack@3 + 22*x10_3*x10_10 + 1111*x10_3^2\n",
      "  + 22*x10_3*x10_4 + 22*x10_3*x10_5 + 22*x10_3*x10_6 + 22*x10_3*x10_7\n",
      "  + 22*x10_3*x10_8 + 22*x10_3*x10_9 + 220*x10_3*y_3_capacity_const@int_slack@0\n",
      "  + 440*x10_3*y_3_capacity_const@int_slack@1\n",
      "  + 880*x10_3*y_3_capacity_const@int_slack@2\n",
      "  + 1760*x10_3*y_3_capacity_const@int_slack@3 + 22*x10_4*x10_10 + 1111*x10_4^2\n",
      "  + 22*x10_4*x10_5 + 22*x10_4*x10_6 + 22*x10_4*x10_7 + 22*x10_4*x10_8\n",
      "  + 22*x10_4*x10_9 + 220*x10_4*y_4_capacity_const@int_slack@0\n",
      "  + 440*x10_4*y_4_capacity_const@int_slack@1\n",
      "  + 880*x10_4*y_4_capacity_const@int_slack@2\n",
      "  + 1760*x10_4*y_4_capacity_const@int_slack@3 + 22*x10_5*x10_10 + 1111*x10_5^2\n",
      "  + 22*x10_5*x10_6 + 22*x10_5*x10_7 + 22*x10_5*x10_8 + 22*x10_5*x10_9\n",
      "  + 220*x10_5*y_5_capacity_const@int_slack@0\n",
      "  + 440*x10_5*y_5_capacity_const@int_slack@1\n",
      "  + 880*x10_5*y_5_capacity_const@int_slack@2\n",
      "  + 1760*x10_5*y_5_capacity_const@int_slack@3 + 22*x10_6*x10_10 + 1111*x10_6^2\n",
      "  + 22*x10_6*x10_7 + 22*x10_6*x10_8 + 22*x10_6*x10_9\n",
      "  + 220*x10_6*y_6_capacity_const@int_slack@0\n",
      "  + 440*x10_6*y_6_capacity_const@int_slack@1\n",
      "  + 880*x10_6*y_6_capacity_const@int_slack@2\n",
      "  + 1760*x10_6*y_6_capacity_const@int_slack@3 + 22*x10_7*x10_10 + 1111*x10_7^2\n",
      "  + 22*x10_7*x10_8 + 22*x10_7*x10_9 + 220*x10_7*y_7_capacity_const@int_slack@0\n",
      "  + 440*x10_7*y_7_capacity_const@int_slack@1\n",
      "  + 880*x10_7*y_7_capacity_const@int_slack@2\n",
      "  + 1760*x10_7*y_7_capacity_const@int_slack@3 + 22*x10_8*x10_10 + 1111*x10_8^2\n",
      "  + 22*x10_8*x10_9 + 220*x10_8*y_8_capacity_const@int_slack@0\n",
      "  + 440*x10_8*y_8_capacity_const@int_slack@1\n",
      "  + 880*x10_8*y_8_capacity_const@int_slack@2\n",
      "  + 1760*x10_8*y_8_capacity_const@int_slack@3 + 22*x10_9*x10_10 + 1111*x10_9^2\n",
      "  + 220*x10_9*y_9_capacity_const@int_slack@0\n",
      "  + 440*x10_9*y_9_capacity_const@int_slack@1\n",
      "  + 880*x10_9*y_9_capacity_const@int_slack@2\n",
      "  + 1760*x10_9*y_9_capacity_const@int_slack@3 + 660*x1_1*x10_1 + 110*x1_1^2\n",
      "  + 22*x1_1*x1_10 + 22*x1_1*x1_2 + 22*x1_1*x1_3 + 22*x1_1*x1_4 + 22*x1_1*x1_5\n",
      "  + 22*x1_1*x1_6 + 22*x1_1*x1_7 + 22*x1_1*x1_8 + 22*x1_1*x1_9 + 132*x1_1*x2_1\n",
      "  + 330*x1_1*x3_1 + 264*x1_1*x4_1 + 462*x1_1*x5_1 + 396*x1_1*x6_1 + 66*x1_1*x7_1\n",
      "  + 528*x1_1*x8_1 + 594*x1_1*x9_1 + 66*x1_1*y_1_capacity_const@int_slack@0\n",
      "  + 132*x1_1*y_1_capacity_const@int_slack@1\n",
      "  + 264*x1_1*y_1_capacity_const@int_slack@2\n",
      "  + 528*x1_1*y_1_capacity_const@int_slack@3 + 660*x1_10*x10_10 + 110*x1_10^2\n",
      "  + 132*x1_10*x2_10 + 330*x1_10*x3_10 + 264*x1_10*x4_10 + 462*x1_10*x5_10\n",
      "  + 396*x1_10*x6_10 + 66*x1_10*x7_10 + 528*x1_10*x8_10 + 594*x1_10*x9_10\n",
      "  + 66*x1_10*y_10_capacity_const@int_slack@0\n",
      "  + 132*x1_10*y_10_capacity_const@int_slack@1\n",
      "  + 264*x1_10*y_10_capacity_const@int_slack@2\n",
      "  + 528*x1_10*y_10_capacity_const@int_slack@3 + 660*x1_2*x10_2 + 22*x1_2*x1_10\n",
      "  + 110*x1_2^2 + 22*x1_2*x1_3 + 22*x1_2*x1_4 + 22*x1_2*x1_5 + 22*x1_2*x1_6\n",
      "  + 22*x1_2*x1_7 + 22*x1_2*x1_8 + 22*x1_2*x1_9 + 132*x1_2*x2_2 + 330*x1_2*x3_2\n",
      "  + 264*x1_2*x4_2 + 462*x1_2*x5_2 + 396*x1_2*x6_2 + 66*x1_2*x7_2 + 528*x1_2*x8_2\n",
      "  + 594*x1_2*x9_2 + 66*x1_2*y_2_capacity_const@int_slack@0\n",
      "  + 132*x1_2*y_2_capacity_const@int_slack@1\n",
      "  + 264*x1_2*y_2_capacity_const@int_slack@2\n",
      "  + 528*x1_2*y_2_capacity_const@int_slack@3 + 660*x1_3*x10_3 + 22*x1_3*x1_10\n",
      "  + 110*x1_3^2 + 22*x1_3*x1_4 + 22*x1_3*x1_5 + 22*x1_3*x1_6 + 22*x1_3*x1_7\n",
      "  + 22*x1_3*x1_8 + 22*x1_3*x1_9 + 132*x1_3*x2_3 + 330*x1_3*x3_3 + 264*x1_3*x4_3\n",
      "  + 462*x1_3*x5_3 + 396*x1_3*x6_3 + 66*x1_3*x7_3 + 528*x1_3*x8_3 + 594*x1_3*x9_3\n",
      "  + 66*x1_3*y_3_capacity_const@int_slack@0\n",
      "  + 132*x1_3*y_3_capacity_const@int_slack@1\n",
      "  + 264*x1_3*y_3_capacity_const@int_slack@2\n",
      "  + 528*x1_3*y_3_capacity_const@int_slack@3 + 660*x1_4*x10_4 + 22*x1_4*x1_10\n",
      "  + 110*x1_4^2 + 22*x1_4*x1_5 + 22*x1_4*x1_6 + 22*x1_4*x1_7 + 22*x1_4*x1_8\n",
      "  + 22*x1_4*x1_9 + 132*x1_4*x2_4 + 330*x1_4*x3_4 + 264*x1_4*x4_4 + 462*x1_4*x5_4\n",
      "  + 396*x1_4*x6_4 + 66*x1_4*x7_4 + 528*x1_4*x8_4 + 594*x1_4*x9_4\n",
      "  + 66*x1_4*y_4_capacity_const@int_slack@0\n",
      "  + 132*x1_4*y_4_capacity_const@int_slack@1\n",
      "  + 264*x1_4*y_4_capacity_const@int_slack@2\n",
      "  + 528*x1_4*y_4_capacity_const@int_slack@3 + 660*x1_5*x10_5 + 22*x1_5*x1_10\n",
      "  + 110*x1_5^2 + 22*x1_5*x1_6 + 22*x1_5*x1_7 + 22*x1_5*x1_8 + 22*x1_5*x1_9\n",
      "  + 132*x1_5*x2_5 + 330*x1_5*x3_5 + 264*x1_5*x4_5 + 462*x1_5*x5_5\n",
      "  + 396*x1_5*x6_5 + 66*x1_5*x7_5 + 528*x1_5*x8_5 + 594*x1_5*x9_5\n",
      "  + 66*x1_5*y_5_capacity_const@int_slack@0\n",
      "  + 132*x1_5*y_5_capacity_const@int_slack@1\n",
      "  + 264*x1_5*y_5_capacity_const@int_slack@2\n",
      "  + 528*x1_5*y_5_capacity_const@int_slack@3 + 660*x1_6*x10_6 + 22*x1_6*x1_10\n",
      "  + 110*x1_6^2 + 22*x1_6*x1_7 + 22*x1_6*x1_8 + 22*x1_6*x1_9 + 132*x1_6*x2_6\n",
      "  + 330*x1_6*x3_6 + 264*x1_6*x4_6 + 462*x1_6*x5_6 + 396*x1_6*x6_6 + 66*x1_6*x7_6\n",
      "  + 528*x1_6*x8_6 + 594*x1_6*x9_6 + 66*x1_6*y_6_capacity_const@int_slack@0\n",
      "  + 132*x1_6*y_6_capacity_const@int_slack@1\n",
      "  + 264*x1_6*y_6_capacity_const@int_slack@2\n",
      "  + 528*x1_6*y_6_capacity_const@int_slack@3 + 660*x1_7*x10_7 + 22*x1_7*x1_10\n",
      "  + 110*x1_7^2 + 22*x1_7*x1_8 + 22*x1_7*x1_9 + 132*x1_7*x2_7 + 330*x1_7*x3_7\n",
      "  + 264*x1_7*x4_7 + 462*x1_7*x5_7 + 396*x1_7*x6_7 + 66*x1_7*x7_7 + 528*x1_7*x8_7\n",
      "  + 594*x1_7*x9_7 + 66*x1_7*y_7_capacity_const@int_slack@0\n",
      "  + 132*x1_7*y_7_capacity_const@int_slack@1\n",
      "  + 264*x1_7*y_7_capacity_const@int_slack@2\n",
      "  + 528*x1_7*y_7_capacity_const@int_slack@3 + 660*x1_8*x10_8 + 22*x1_8*x1_10\n",
      "  + 110*x1_8^2 + 22*x1_8*x1_9 + 132*x1_8*x2_8 + 330*x1_8*x3_8 + 264*x1_8*x4_8\n",
      "  + 462*x1_8*x5_8 + 396*x1_8*x6_8 + 66*x1_8*x7_8 + 528*x1_8*x8_8 + 594*x1_8*x9_8\n",
      "  + 66*x1_8*y_8_capacity_const@int_slack@0\n",
      "  + 132*x1_8*y_8_capacity_const@int_slack@1\n",
      "  + 264*x1_8*y_8_capacity_const@int_slack@2\n",
      "  + 528*x1_8*y_8_capacity_const@int_slack@3 + 660*x1_9*x10_9 + 22*x1_9*x1_10\n",
      "  + 110*x1_9^2 + 132*x1_9*x2_9 + 330*x1_9*x3_9 + 264*x1_9*x4_9 + 462*x1_9*x5_9\n",
      "  + 396*x1_9*x6_9 + 66*x1_9*x7_9 + 528*x1_9*x8_9 + 594*x1_9*x9_9\n",
      "  + 66*x1_9*y_9_capacity_const@int_slack@0\n",
      "  + 132*x1_9*y_9_capacity_const@int_slack@1\n",
      "  + 264*x1_9*y_9_capacity_const@int_slack@2\n",
      "  + 528*x1_9*y_9_capacity_const@int_slack@3 + 440*x2_1*x10_1 + 55*x2_1^2\n",
      "  + 22*x2_1*x2_10 + 22*x2_1*x2_2 + 22*x2_1*x2_3 + 22*x2_1*x2_4 + 22*x2_1*x2_5\n",
      "  + 22*x2_1*x2_6 + 22*x2_1*x2_7 + 22*x2_1*x2_8 + 22*x2_1*x2_9 + 220*x2_1*x3_1\n",
      "  + 176*x2_1*x4_1 + 308*x2_1*x5_1 + 264*x2_1*x6_1 + 44*x2_1*x7_1 + 352*x2_1*x8_1\n",
      "  + 396*x2_1*x9_1 + 44*x2_1*y_1_capacity_const@int_slack@0\n",
      "  + 88*x2_1*y_1_capacity_const@int_slack@1\n",
      "  + 176*x2_1*y_1_capacity_const@int_slack@2\n",
      "  + 352*x2_1*y_1_capacity_const@int_slack@3 + 440*x2_10*x10_10 + 55*x2_10^2\n",
      "  + 220*x2_10*x3_10 + 176*x2_10*x4_10 + 308*x2_10*x5_10 + 264*x2_10*x6_10\n",
      "  + 44*x2_10*x7_10 + 352*x2_10*x8_10 + 396*x2_10*x9_10\n",
      "  + 44*x2_10*y_10_capacity_const@int_slack@0\n",
      "  + 88*x2_10*y_10_capacity_const@int_slack@1\n",
      "  + 176*x2_10*y_10_capacity_const@int_slack@2\n",
      "  + 352*x2_10*y_10_capacity_const@int_slack@3 + 440*x2_2*x10_2 + 22*x2_2*x2_10\n",
      "  + 55*x2_2^2 + 22*x2_2*x2_3 + 22*x2_2*x2_4 + 22*x2_2*x2_5 + 22*x2_2*x2_6\n",
      "  + 22*x2_2*x2_7 + 22*x2_2*x2_8 + 22*x2_2*x2_9 + 220*x2_2*x3_2 + 176*x2_2*x4_2\n",
      "  + 308*x2_2*x5_2 + 264*x2_2*x6_2 + 44*x2_2*x7_2 + 352*x2_2*x8_2 + 396*x2_2*x9_2\n",
      "  + 44*x2_2*y_2_capacity_const@int_slack@0\n",
      "  + 88*x2_2*y_2_capacity_const@int_slack@1\n",
      "  + 176*x2_2*y_2_capacity_const@int_slack@2\n",
      "  + 352*x2_2*y_2_capacity_const@int_slack@3 + 440*x2_3*x10_3 + 22*x2_3*x2_10\n",
      "  + 55*x2_3^2 + 22*x2_3*x2_4 + 22*x2_3*x2_5 + 22*x2_3*x2_6 + 22*x2_3*x2_7\n",
      "  + 22*x2_3*x2_8 + 22*x2_3*x2_9 + 220*x2_3*x3_3 + 176*x2_3*x4_3 + 308*x2_3*x5_3\n",
      "  + 264*x2_3*x6_3 + 44*x2_3*x7_3 + 352*x2_3*x8_3 + 396*x2_3*x9_3\n",
      "  + 44*x2_3*y_3_capacity_const@int_slack@0\n",
      "  + 88*x2_3*y_3_capacity_const@int_slack@1\n",
      "  + 176*x2_3*y_3_capacity_const@int_slack@2\n",
      "  + 352*x2_3*y_3_capacity_const@int_slack@3 + 440*x2_4*x10_4 + 22*x2_4*x2_10\n",
      "  + 55*x2_4^2 + 22*x2_4*x2_5 + 22*x2_4*x2_6 + 22*x2_4*x2_7 + 22*x2_4*x2_8\n",
      "  + 22*x2_4*x2_9 + 220*x2_4*x3_4 + 176*x2_4*x4_4 + 308*x2_4*x5_4 + 264*x2_4*x6_4\n",
      "  + 44*x2_4*x7_4 + 352*x2_4*x8_4 + 396*x2_4*x9_4\n",
      "  + 44*x2_4*y_4_capacity_const@int_slack@0\n",
      "  + 88*x2_4*y_4_capacity_const@int_slack@1\n",
      "  + 176*x2_4*y_4_capacity_const@int_slack@2\n",
      "  + 352*x2_4*y_4_capacity_const@int_slack@3 + 440*x2_5*x10_5 + 22*x2_5*x2_10\n",
      "  + 55*x2_5^2 + 22*x2_5*x2_6 + 22*x2_5*x2_7 + 22*x2_5*x2_8 + 22*x2_5*x2_9\n",
      "  + 220*x2_5*x3_5 + 176*x2_5*x4_5 + 308*x2_5*x5_5 + 264*x2_5*x6_5 + 44*x2_5*x7_5\n",
      "  + 352*x2_5*x8_5 + 396*x2_5*x9_5 + 44*x2_5*y_5_capacity_const@int_slack@0\n",
      "  + 88*x2_5*y_5_capacity_const@int_slack@1\n",
      "  + 176*x2_5*y_5_capacity_const@int_slack@2\n",
      "  + 352*x2_5*y_5_capacity_const@int_slack@3 + 440*x2_6*x10_6 + 22*x2_6*x2_10\n",
      "  + 55*x2_6^2 + 22*x2_6*x2_7 + 22*x2_6*x2_8 + 22*x2_6*x2_9 + 220*x2_6*x3_6\n",
      "  + 176*x2_6*x4_6 + 308*x2_6*x5_6 + 264*x2_6*x6_6 + 44*x2_6*x7_6 + 352*x2_6*x8_6\n",
      "  + 396*x2_6*x9_6 + 44*x2_6*y_6_capacity_const@int_slack@0\n",
      "  + 88*x2_6*y_6_capacity_const@int_slack@1\n",
      "  + 176*x2_6*y_6_capacity_const@int_slack@2\n",
      "  + 352*x2_6*y_6_capacity_const@int_slack@3 + 440*x2_7*x10_7 + 22*x2_7*x2_10\n",
      "  + 55*x2_7^2 + 22*x2_7*x2_8 + 22*x2_7*x2_9 + 220*x2_7*x3_7 + 176*x2_7*x4_7\n",
      "  + 308*x2_7*x5_7 + 264*x2_7*x6_7 + 44*x2_7*x7_7 + 352*x2_7*x8_7 + 396*x2_7*x9_7\n",
      "  + 44*x2_7*y_7_capacity_const@int_slack@0\n",
      "  + 88*x2_7*y_7_capacity_const@int_slack@1\n",
      "  + 176*x2_7*y_7_capacity_const@int_slack@2\n",
      "  + 352*x2_7*y_7_capacity_const@int_slack@3 + 440*x2_8*x10_8 + 22*x2_8*x2_10\n",
      "  + 55*x2_8^2 + 22*x2_8*x2_9 + 220*x2_8*x3_8 + 176*x2_8*x4_8 + 308*x2_8*x5_8\n",
      "  + 264*x2_8*x6_8 + 44*x2_8*x7_8 + 352*x2_8*x8_8 + 396*x2_8*x9_8\n",
      "  + 44*x2_8*y_8_capacity_const@int_slack@0\n",
      "  + 88*x2_8*y_8_capacity_const@int_slack@1\n",
      "  + 176*x2_8*y_8_capacity_const@int_slack@2\n",
      "  + 352*x2_8*y_8_capacity_const@int_slack@3 + 440*x2_9*x10_9 + 22*x2_9*x2_10\n",
      "  + 55*x2_9^2 + 220*x2_9*x3_9 + 176*x2_9*x4_9 + 308*x2_9*x5_9 + 264*x2_9*x6_9\n",
      "  + 44*x2_9*x7_9 + 352*x2_9*x8_9 + 396*x2_9*x9_9\n",
      "  + 44*x2_9*y_9_capacity_const@int_slack@0\n",
      "  + 88*x2_9*y_9_capacity_const@int_slack@1\n",
      "  + 176*x2_9*y_9_capacity_const@int_slack@2\n",
      "  + 352*x2_9*y_9_capacity_const@int_slack@3 + 1100*x3_1*x10_1 + 286*x3_1^2\n",
      "  + 22*x3_1*x3_10 + 22*x3_1*x3_2 + 22*x3_1*x3_3 + 22*x3_1*x3_4 + 22*x3_1*x3_5\n",
      "  + 22*x3_1*x3_6 + 22*x3_1*x3_7 + 22*x3_1*x3_8 + 22*x3_1*x3_9 + 440*x3_1*x4_1\n",
      "  + 770*x3_1*x5_1 + 660*x3_1*x6_1 + 110*x3_1*x7_1 + 880*x3_1*x8_1\n",
      "  + 990*x3_1*x9_1 + 110*x3_1*y_1_capacity_const@int_slack@0\n",
      "  + 220*x3_1*y_1_capacity_const@int_slack@1\n",
      "  + 440*x3_1*y_1_capacity_const@int_slack@2\n",
      "  + 880*x3_1*y_1_capacity_const@int_slack@3 + 1100*x3_10*x10_10 + 286*x3_10^2\n",
      "  + 440*x3_10*x4_10 + 770*x3_10*x5_10 + 660*x3_10*x6_10 + 110*x3_10*x7_10\n",
      "  + 880*x3_10*x8_10 + 990*x3_10*x9_10\n",
      "  + 110*x3_10*y_10_capacity_const@int_slack@0\n",
      "  + 220*x3_10*y_10_capacity_const@int_slack@1\n",
      "  + 440*x3_10*y_10_capacity_const@int_slack@2\n",
      "  + 880*x3_10*y_10_capacity_const@int_slack@3 + 1100*x3_2*x10_2 + 22*x3_2*x3_10\n",
      "  + 286*x3_2^2 + 22*x3_2*x3_3 + 22*x3_2*x3_4 + 22*x3_2*x3_5 + 22*x3_2*x3_6\n",
      "  + 22*x3_2*x3_7 + 22*x3_2*x3_8 + 22*x3_2*x3_9 + 440*x3_2*x4_2 + 770*x3_2*x5_2\n",
      "  + 660*x3_2*x6_2 + 110*x3_2*x7_2 + 880*x3_2*x8_2 + 990*x3_2*x9_2\n",
      "  + 110*x3_2*y_2_capacity_const@int_slack@0\n",
      "  + 220*x3_2*y_2_capacity_const@int_slack@1\n",
      "  + 440*x3_2*y_2_capacity_const@int_slack@2\n",
      "  + 880*x3_2*y_2_capacity_const@int_slack@3 + 1100*x3_3*x10_3 + 22*x3_3*x3_10\n",
      "  + 286*x3_3^2 + 22*x3_3*x3_4 + 22*x3_3*x3_5 + 22*x3_3*x3_6 + 22*x3_3*x3_7\n",
      "  + 22*x3_3*x3_8 + 22*x3_3*x3_9 + 440*x3_3*x4_3 + 770*x3_3*x5_3 + 660*x3_3*x6_3\n",
      "  + 110*x3_3*x7_3 + 880*x3_3*x8_3 + 990*x3_3*x9_3\n",
      "  + 110*x3_3*y_3_capacity_const@int_slack@0\n",
      "  + 220*x3_3*y_3_capacity_const@int_slack@1\n",
      "  + 440*x3_3*y_3_capacity_const@int_slack@2\n",
      "  + 880*x3_3*y_3_capacity_const@int_slack@3 + 1100*x3_4*x10_4 + 22*x3_4*x3_10\n",
      "  + 286*x3_4^2 + 22*x3_4*x3_5 + 22*x3_4*x3_6 + 22*x3_4*x3_7 + 22*x3_4*x3_8\n",
      "  + 22*x3_4*x3_9 + 440*x3_4*x4_4 + 770*x3_4*x5_4 + 660*x3_4*x6_4 + 110*x3_4*x7_4\n",
      "  + 880*x3_4*x8_4 + 990*x3_4*x9_4 + 110*x3_4*y_4_capacity_const@int_slack@0\n",
      "  + 220*x3_4*y_4_capacity_const@int_slack@1\n",
      "  + 440*x3_4*y_4_capacity_const@int_slack@2\n",
      "  + 880*x3_4*y_4_capacity_const@int_slack@3 + 1100*x3_5*x10_5 + 22*x3_5*x3_10\n",
      "  + 286*x3_5^2 + 22*x3_5*x3_6 + 22*x3_5*x3_7 + 22*x3_5*x3_8 + 22*x3_5*x3_9\n",
      "  + 440*x3_5*x4_5 + 770*x3_5*x5_5 + 660*x3_5*x6_5 + 110*x3_5*x7_5\n",
      "  + 880*x3_5*x8_5 + 990*x3_5*x9_5 + 110*x3_5*y_5_capacity_const@int_slack@0\n",
      "  + 220*x3_5*y_5_capacity_const@int_slack@1\n",
      "  + 440*x3_5*y_5_capacity_const@int_slack@2\n",
      "  + 880*x3_5*y_5_capacity_const@int_slack@3 + 1100*x3_6*x10_6 + 22*x3_6*x3_10\n",
      "  + 286*x3_6^2 + 22*x3_6*x3_7 + 22*x3_6*x3_8 + 22*x3_6*x3_9 + 440*x3_6*x4_6\n",
      "  + 770*x3_6*x5_6 + 660*x3_6*x6_6 + 110*x3_6*x7_6 + 880*x3_6*x8_6\n",
      "  + 990*x3_6*x9_6 + 110*x3_6*y_6_capacity_const@int_slack@0\n",
      "  + 220*x3_6*y_6_capacity_const@int_slack@1\n",
      "  + 440*x3_6*y_6_capacity_const@int_slack@2\n",
      "  + 880*x3_6*y_6_capacity_const@int_slack@3 + 1100*x3_7*x10_7 + 22*x3_7*x3_10\n",
      "  + 286*x3_7^2 + 22*x3_7*x3_8 + 22*x3_7*x3_9 + 440*x3_7*x4_7 + 770*x3_7*x5_7\n",
      "  + 660*x3_7*x6_7 + 110*x3_7*x7_7 + 880*x3_7*x8_7 + 990*x3_7*x9_7\n",
      "  + 110*x3_7*y_7_capacity_const@int_slack@0\n",
      "  + 220*x3_7*y_7_capacity_const@int_slack@1\n",
      "  + 440*x3_7*y_7_capacity_const@int_slack@2\n",
      "  + 880*x3_7*y_7_capacity_const@int_slack@3 + 1100*x3_8*x10_8 + 22*x3_8*x3_10\n",
      "  + 286*x3_8^2 + 22*x3_8*x3_9 + 440*x3_8*x4_8 + 770*x3_8*x5_8 + 660*x3_8*x6_8\n",
      "  + 110*x3_8*x7_8 + 880*x3_8*x8_8 + 990*x3_8*x9_8\n",
      "  + 110*x3_8*y_8_capacity_const@int_slack@0\n",
      "  + 220*x3_8*y_8_capacity_const@int_slack@1\n",
      "  + 440*x3_8*y_8_capacity_const@int_slack@2\n",
      "  + 880*x3_8*y_8_capacity_const@int_slack@3 + 1100*x3_9*x10_9 + 22*x3_9*x3_10\n",
      "  + 286*x3_9^2 + 440*x3_9*x4_9 + 770*x3_9*x5_9 + 660*x3_9*x6_9 + 110*x3_9*x7_9\n",
      "  + 880*x3_9*x8_9 + 990*x3_9*x9_9 + 110*x3_9*y_9_capacity_const@int_slack@0\n",
      "  + 220*x3_9*y_9_capacity_const@int_slack@1\n",
      "  + 440*x3_9*y_9_capacity_const@int_slack@2\n",
      "  + 880*x3_9*y_9_capacity_const@int_slack@3 + 880*x4_1*x10_1 + 187*x4_1^2\n",
      "  + 22*x4_1*x4_10 + 22*x4_1*x4_2 + 22*x4_1*x4_3 + 22*x4_1*x4_4 + 22*x4_1*x4_5\n",
      "  + 22*x4_1*x4_6 + 22*x4_1*x4_7 + 22*x4_1*x4_8 + 22*x4_1*x4_9 + 616*x4_1*x5_1\n",
      "  + 528*x4_1*x6_1 + 88*x4_1*x7_1 + 704*x4_1*x8_1 + 792*x4_1*x9_1\n",
      "  + 88*x4_1*y_1_capacity_const@int_slack@0\n",
      "  + 176*x4_1*y_1_capacity_const@int_slack@1\n",
      "  + 352*x4_1*y_1_capacity_const@int_slack@2\n",
      "  + 704*x4_1*y_1_capacity_const@int_slack@3 + 880*x4_10*x10_10 + 187*x4_10^2\n",
      "  + 616*x4_10*x5_10 + 528*x4_10*x6_10 + 88*x4_10*x7_10 + 704*x4_10*x8_10\n",
      "  + 792*x4_10*x9_10 + 88*x4_10*y_10_capacity_const@int_slack@0\n",
      "  + 176*x4_10*y_10_capacity_const@int_slack@1\n",
      "  + 352*x4_10*y_10_capacity_const@int_slack@2\n",
      "  + 704*x4_10*y_10_capacity_const@int_slack@3 + 880*x4_2*x10_2 + 22*x4_2*x4_10\n",
      "  + 187*x4_2^2 + 22*x4_2*x4_3 + 22*x4_2*x4_4 + 22*x4_2*x4_5 + 22*x4_2*x4_6\n",
      "  + 22*x4_2*x4_7 + 22*x4_2*x4_8 + 22*x4_2*x4_9 + 616*x4_2*x5_2 + 528*x4_2*x6_2\n",
      "  + 88*x4_2*x7_2 + 704*x4_2*x8_2 + 792*x4_2*x9_2\n",
      "  + 88*x4_2*y_2_capacity_const@int_slack@0\n",
      "  + 176*x4_2*y_2_capacity_const@int_slack@1\n",
      "  + 352*x4_2*y_2_capacity_const@int_slack@2\n",
      "  + 704*x4_2*y_2_capacity_const@int_slack@3 + 880*x4_3*x10_3 + 22*x4_3*x4_10\n",
      "  + 187*x4_3^2 + 22*x4_3*x4_4 + 22*x4_3*x4_5 + 22*x4_3*x4_6 + 22*x4_3*x4_7\n",
      "  + 22*x4_3*x4_8 + 22*x4_3*x4_9 + 616*x4_3*x5_3 + 528*x4_3*x6_3 + 88*x4_3*x7_3\n",
      "  + 704*x4_3*x8_3 + 792*x4_3*x9_3 + 88*x4_3*y_3_capacity_const@int_slack@0\n",
      "  + 176*x4_3*y_3_capacity_const@int_slack@1\n",
      "  + 352*x4_3*y_3_capacity_const@int_slack@2\n",
      "  + 704*x4_3*y_3_capacity_const@int_slack@3 + 880*x4_4*x10_4 + 22*x4_4*x4_10\n",
      "  + 187*x4_4^2 + 22*x4_4*x4_5 + 22*x4_4*x4_6 + 22*x4_4*x4_7 + 22*x4_4*x4_8\n",
      "  + 22*x4_4*x4_9 + 616*x4_4*x5_4 + 528*x4_4*x6_4 + 88*x4_4*x7_4 + 704*x4_4*x8_4\n",
      "  + 792*x4_4*x9_4 + 88*x4_4*y_4_capacity_const@int_slack@0\n",
      "  + 176*x4_4*y_4_capacity_const@int_slack@1\n",
      "  + 352*x4_4*y_4_capacity_const@int_slack@2\n",
      "  + 704*x4_4*y_4_capacity_const@int_slack@3 + 880*x4_5*x10_5 + 22*x4_5*x4_10\n",
      "  + 187*x4_5^2 + 22*x4_5*x4_6 + 22*x4_5*x4_7 + 22*x4_5*x4_8 + 22*x4_5*x4_9\n",
      "  + 616*x4_5*x5_5 + 528*x4_5*x6_5 + 88*x4_5*x7_5 + 704*x4_5*x8_5 + 792*x4_5*x9_5\n",
      "  + 88*x4_5*y_5_capacity_const@int_slack@0\n",
      "  + 176*x4_5*y_5_capacity_const@int_slack@1\n",
      "  + 352*x4_5*y_5_capacity_const@int_slack@2\n",
      "  + 704*x4_5*y_5_capacity_const@int_slack@3 + 880*x4_6*x10_6 + 22*x4_6*x4_10\n",
      "  + 187*x4_6^2 + 22*x4_6*x4_7 + 22*x4_6*x4_8 + 22*x4_6*x4_9 + 616*x4_6*x5_6\n",
      "  + 528*x4_6*x6_6 + 88*x4_6*x7_6 + 704*x4_6*x8_6 + 792*x4_6*x9_6\n",
      "  + 88*x4_6*y_6_capacity_const@int_slack@0\n",
      "  + 176*x4_6*y_6_capacity_const@int_slack@1\n",
      "  + 352*x4_6*y_6_capacity_const@int_slack@2\n",
      "  + 704*x4_6*y_6_capacity_const@int_slack@3 + 880*x4_7*x10_7 + 22*x4_7*x4_10\n",
      "  + 187*x4_7^2 + 22*x4_7*x4_8 + 22*x4_7*x4_9 + 616*x4_7*x5_7 + 528*x4_7*x6_7\n",
      "  + 88*x4_7*x7_7 + 704*x4_7*x8_7 + 792*x4_7*x9_7\n",
      "  + 88*x4_7*y_7_capacity_const@int_slack@0\n",
      "  + 176*x4_7*y_7_capacity_const@int_slack@1\n",
      "  + 352*x4_7*y_7_capacity_const@int_slack@2\n",
      "  + 704*x4_7*y_7_capacity_const@int_slack@3 + 880*x4_8*x10_8 + 22*x4_8*x4_10\n",
      "  + 187*x4_8^2 + 22*x4_8*x4_9 + 616*x4_8*x5_8 + 528*x4_8*x6_8 + 88*x4_8*x7_8\n",
      "  + 704*x4_8*x8_8 + 792*x4_8*x9_8 + 88*x4_8*y_8_capacity_const@int_slack@0\n",
      "  + 176*x4_8*y_8_capacity_const@int_slack@1\n",
      "  + 352*x4_8*y_8_capacity_const@int_slack@2\n",
      "  + 704*x4_8*y_8_capacity_const@int_slack@3 + 880*x4_9*x10_9 + 22*x4_9*x4_10\n",
      "  + 187*x4_9^2 + 616*x4_9*x5_9 + 528*x4_9*x6_9 + 88*x4_9*x7_9 + 704*x4_9*x8_9\n",
      "  + 792*x4_9*x9_9 + 88*x4_9*y_9_capacity_const@int_slack@0\n",
      "  + 176*x4_9*y_9_capacity_const@int_slack@1\n",
      "  + 352*x4_9*y_9_capacity_const@int_slack@2\n",
      "  + 704*x4_9*y_9_capacity_const@int_slack@3 + 1540*x5_1*x10_1 + 550*x5_1^2\n",
      "  + 22*x5_1*x5_10 + 22*x5_1*x5_2 + 22*x5_1*x5_3 + 22*x5_1*x5_4 + 22*x5_1*x5_5\n",
      "  + 22*x5_1*x5_6 + 22*x5_1*x5_7 + 22*x5_1*x5_8 + 22*x5_1*x5_9 + 924*x5_1*x6_1\n",
      "  + 154*x5_1*x7_1 + 1232*x5_1*x8_1 + 1386*x5_1*x9_1\n",
      "  + 154*x5_1*y_1_capacity_const@int_slack@0\n",
      "  + 308*x5_1*y_1_capacity_const@int_slack@1\n",
      "  + 616*x5_1*y_1_capacity_const@int_slack@2\n",
      "  + 1232*x5_1*y_1_capacity_const@int_slack@3 + 1540*x5_10*x10_10 + 550*x5_10^2\n",
      "  + 924*x5_10*x6_10 + 154*x5_10*x7_10 + 1232*x5_10*x8_10 + 1386*x5_10*x9_10\n",
      "  + 154*x5_10*y_10_capacity_const@int_slack@0\n",
      "  + 308*x5_10*y_10_capacity_const@int_slack@1\n",
      "  + 616*x5_10*y_10_capacity_const@int_slack@2\n",
      "  + 1232*x5_10*y_10_capacity_const@int_slack@3 + 1540*x5_2*x10_2 + 22*x5_2*x5_10\n",
      "  + 550*x5_2^2 + 22*x5_2*x5_3 + 22*x5_2*x5_4 + 22*x5_2*x5_5 + 22*x5_2*x5_6\n",
      "  + 22*x5_2*x5_7 + 22*x5_2*x5_8 + 22*x5_2*x5_9 + 924*x5_2*x6_2 + 154*x5_2*x7_2\n",
      "  + 1232*x5_2*x8_2 + 1386*x5_2*x9_2 + 154*x5_2*y_2_capacity_const@int_slack@0\n",
      "  + 308*x5_2*y_2_capacity_const@int_slack@1\n",
      "  + 616*x5_2*y_2_capacity_const@int_slack@2\n",
      "  + 1232*x5_2*y_2_capacity_const@int_slack@3 + 1540*x5_3*x10_3 + 22*x5_3*x5_10\n",
      "  + 550*x5_3^2 + 22*x5_3*x5_4 + 22*x5_3*x5_5 + 22*x5_3*x5_6 + 22*x5_3*x5_7\n",
      "  + 22*x5_3*x5_8 + 22*x5_3*x5_9 + 924*x5_3*x6_3 + 154*x5_3*x7_3 + 1232*x5_3*x8_3\n",
      "  + 1386*x5_3*x9_3 + 154*x5_3*y_3_capacity_const@int_slack@0\n",
      "  + 308*x5_3*y_3_capacity_const@int_slack@1\n",
      "  + 616*x5_3*y_3_capacity_const@int_slack@2\n",
      "  + 1232*x5_3*y_3_capacity_const@int_slack@3 + 1540*x5_4*x10_4 + 22*x5_4*x5_10\n",
      "  + 550*x5_4^2 + 22*x5_4*x5_5 + 22*x5_4*x5_6 + 22*x5_4*x5_7 + 22*x5_4*x5_8\n",
      "  + 22*x5_4*x5_9 + 924*x5_4*x6_4 + 154*x5_4*x7_4 + 1232*x5_4*x8_4\n",
      "  + 1386*x5_4*x9_4 + 154*x5_4*y_4_capacity_const@int_slack@0\n",
      "  + 308*x5_4*y_4_capacity_const@int_slack@1\n",
      "  + 616*x5_4*y_4_capacity_const@int_slack@2\n",
      "  + 1232*x5_4*y_4_capacity_const@int_slack@3 + 1540*x5_5*x10_5 + 22*x5_5*x5_10\n",
      "  + 550*x5_5^2 + 22*x5_5*x5_6 + 22*x5_5*x5_7 + 22*x5_5*x5_8 + 22*x5_5*x5_9\n",
      "  + 924*x5_5*x6_5 + 154*x5_5*x7_5 + 1232*x5_5*x8_5 + 1386*x5_5*x9_5\n",
      "  + 154*x5_5*y_5_capacity_const@int_slack@0\n",
      "  + 308*x5_5*y_5_capacity_const@int_slack@1\n",
      "  + 616*x5_5*y_5_capacity_const@int_slack@2\n",
      "  + 1232*x5_5*y_5_capacity_const@int_slack@3 + 1540*x5_6*x10_6 + 22*x5_6*x5_10\n",
      "  + 550*x5_6^2 + 22*x5_6*x5_7 + 22*x5_6*x5_8 + 22*x5_6*x5_9 + 924*x5_6*x6_6\n",
      "  + 154*x5_6*x7_6 + 1232*x5_6*x8_6 + 1386*x5_6*x9_6\n",
      "  + 154*x5_6*y_6_capacity_const@int_slack@0\n",
      "  + 308*x5_6*y_6_capacity_const@int_slack@1\n",
      "  + 616*x5_6*y_6_capacity_const@int_slack@2\n",
      "  + 1232*x5_6*y_6_capacity_const@int_slack@3 + 1540*x5_7*x10_7 + 22*x5_7*x5_10\n",
      "  + 550*x5_7^2 + 22*x5_7*x5_8 + 22*x5_7*x5_9 + 924*x5_7*x6_7 + 154*x5_7*x7_7\n",
      "  + 1232*x5_7*x8_7 + 1386*x5_7*x9_7 + 154*x5_7*y_7_capacity_const@int_slack@0\n",
      "  + 308*x5_7*y_7_capacity_const@int_slack@1\n",
      "  + 616*x5_7*y_7_capacity_const@int_slack@2\n",
      "  + 1232*x5_7*y_7_capacity_const@int_slack@3 + 1540*x5_8*x10_8 + 22*x5_8*x5_10\n",
      "  + 550*x5_8^2 + 22*x5_8*x5_9 + 924*x5_8*x6_8 + 154*x5_8*x7_8 + 1232*x5_8*x8_8\n",
      "  + 1386*x5_8*x9_8 + 154*x5_8*y_8_capacity_const@int_slack@0\n",
      "  + 308*x5_8*y_8_capacity_const@int_slack@1\n",
      "  + 616*x5_8*y_8_capacity_const@int_slack@2\n",
      "  + 1232*x5_8*y_8_capacity_const@int_slack@3 + 1540*x5_9*x10_9 + 22*x5_9*x5_10\n",
      "  + 550*x5_9^2 + 924*x5_9*x6_9 + 154*x5_9*x7_9 + 1232*x5_9*x8_9 + 1386*x5_9*x9_9\n",
      "  + 154*x5_9*y_9_capacity_const@int_slack@0\n",
      "  + 308*x5_9*y_9_capacity_const@int_slack@1\n",
      "  + 616*x5_9*y_9_capacity_const@int_slack@2\n",
      "  + 1232*x5_9*y_9_capacity_const@int_slack@3 + 1320*x6_1*x10_1 + 407*x6_1^2\n",
      "  + 22*x6_1*x6_10 + 22*x6_1*x6_2 + 22*x6_1*x6_3 + 22*x6_1*x6_4 + 22*x6_1*x6_5\n",
      "  + 22*x6_1*x6_6 + 22*x6_1*x6_7 + 22*x6_1*x6_8 + 22*x6_1*x6_9 + 132*x6_1*x7_1\n",
      "  + 1056*x6_1*x8_1 + 1188*x6_1*x9_1 + 132*x6_1*y_1_capacity_const@int_slack@0\n",
      "  + 264*x6_1*y_1_capacity_const@int_slack@1\n",
      "  + 528*x6_1*y_1_capacity_const@int_slack@2\n",
      "  + 1056*x6_1*y_1_capacity_const@int_slack@3 + 1320*x6_10*x10_10 + 407*x6_10^2\n",
      "  + 132*x6_10*x7_10 + 1056*x6_10*x8_10 + 1188*x6_10*x9_10\n",
      "  + 132*x6_10*y_10_capacity_const@int_slack@0\n",
      "  + 264*x6_10*y_10_capacity_const@int_slack@1\n",
      "  + 528*x6_10*y_10_capacity_const@int_slack@2\n",
      "  + 1056*x6_10*y_10_capacity_const@int_slack@3 + 1320*x6_2*x10_2 + 22*x6_2*x6_10\n",
      "  + 407*x6_2^2 + 22*x6_2*x6_3 + 22*x6_2*x6_4 + 22*x6_2*x6_5 + 22*x6_2*x6_6\n",
      "  + 22*x6_2*x6_7 + 22*x6_2*x6_8 + 22*x6_2*x6_9 + 132*x6_2*x7_2 + 1056*x6_2*x8_2\n",
      "  + 1188*x6_2*x9_2 + 132*x6_2*y_2_capacity_const@int_slack@0\n",
      "  + 264*x6_2*y_2_capacity_const@int_slack@1\n",
      "  + 528*x6_2*y_2_capacity_const@int_slack@2\n",
      "  + 1056*x6_2*y_2_capacity_const@int_slack@3 + 1320*x6_3*x10_3 + 22*x6_3*x6_10\n",
      "  + 407*x6_3^2 + 22*x6_3*x6_4 + 22*x6_3*x6_5 + 22*x6_3*x6_6 + 22*x6_3*x6_7\n",
      "  + 22*x6_3*x6_8 + 22*x6_3*x6_9 + 132*x6_3*x7_3 + 1056*x6_3*x8_3\n",
      "  + 1188*x6_3*x9_3 + 132*x6_3*y_3_capacity_const@int_slack@0\n",
      "  + 264*x6_3*y_3_capacity_const@int_slack@1\n",
      "  + 528*x6_3*y_3_capacity_const@int_slack@2\n",
      "  + 1056*x6_3*y_3_capacity_const@int_slack@3 + 1320*x6_4*x10_4 + 22*x6_4*x6_10\n",
      "  + 407*x6_4^2 + 22*x6_4*x6_5 + 22*x6_4*x6_6 + 22*x6_4*x6_7 + 22*x6_4*x6_8\n",
      "  + 22*x6_4*x6_9 + 132*x6_4*x7_4 + 1056*x6_4*x8_4 + 1188*x6_4*x9_4\n",
      "  + 132*x6_4*y_4_capacity_const@int_slack@0\n",
      "  + 264*x6_4*y_4_capacity_const@int_slack@1\n",
      "  + 528*x6_4*y_4_capacity_const@int_slack@2\n",
      "  + 1056*x6_4*y_4_capacity_const@int_slack@3 + 1320*x6_5*x10_5 + 22*x6_5*x6_10\n",
      "  + 407*x6_5^2 + 22*x6_5*x6_6 + 22*x6_5*x6_7 + 22*x6_5*x6_8 + 22*x6_5*x6_9\n",
      "  + 132*x6_5*x7_5 + 1056*x6_5*x8_5 + 1188*x6_5*x9_5\n",
      "  + 132*x6_5*y_5_capacity_const@int_slack@0\n",
      "  + 264*x6_5*y_5_capacity_const@int_slack@1\n",
      "  + 528*x6_5*y_5_capacity_const@int_slack@2\n",
      "  + 1056*x6_5*y_5_capacity_const@int_slack@3 + 1320*x6_6*x10_6 + 22*x6_6*x6_10\n",
      "  + 407*x6_6^2 + 22*x6_6*x6_7 + 22*x6_6*x6_8 + 22*x6_6*x6_9 + 132*x6_6*x7_6\n",
      "  + 1056*x6_6*x8_6 + 1188*x6_6*x9_6 + 132*x6_6*y_6_capacity_const@int_slack@0\n",
      "  + 264*x6_6*y_6_capacity_const@int_slack@1\n",
      "  + 528*x6_6*y_6_capacity_const@int_slack@2\n",
      "  + 1056*x6_6*y_6_capacity_const@int_slack@3 + 1320*x6_7*x10_7 + 22*x6_7*x6_10\n",
      "  + 407*x6_7^2 + 22*x6_7*x6_8 + 22*x6_7*x6_9 + 132*x6_7*x7_7 + 1056*x6_7*x8_7\n",
      "  + 1188*x6_7*x9_7 + 132*x6_7*y_7_capacity_const@int_slack@0\n",
      "  + 264*x6_7*y_7_capacity_const@int_slack@1\n",
      "  + 528*x6_7*y_7_capacity_const@int_slack@2\n",
      "  + 1056*x6_7*y_7_capacity_const@int_slack@3 + 1320*x6_8*x10_8 + 22*x6_8*x6_10\n",
      "  + 407*x6_8^2 + 22*x6_8*x6_9 + 132*x6_8*x7_8 + 1056*x6_8*x8_8 + 1188*x6_8*x9_8\n",
      "  + 132*x6_8*y_8_capacity_const@int_slack@0\n",
      "  + 264*x6_8*y_8_capacity_const@int_slack@1\n",
      "  + 528*x6_8*y_8_capacity_const@int_slack@2\n",
      "  + 1056*x6_8*y_8_capacity_const@int_slack@3 + 1320*x6_9*x10_9 + 22*x6_9*x6_10\n",
      "  + 407*x6_9^2 + 132*x6_9*x7_9 + 1056*x6_9*x8_9 + 1188*x6_9*x9_9\n",
      "  + 132*x6_9*y_9_capacity_const@int_slack@0\n",
      "  + 264*x6_9*y_9_capacity_const@int_slack@1\n",
      "  + 528*x6_9*y_9_capacity_const@int_slack@2\n",
      "  + 1056*x6_9*y_9_capacity_const@int_slack@3 + 220*x7_1*x10_1 + 22*x7_1^2\n",
      "  + 22*x7_1*x7_10 + 22*x7_1*x7_2 + 22*x7_1*x7_3 + 22*x7_1*x7_4 + 22*x7_1*x7_5\n",
      "  + 22*x7_1*x7_6 + 22*x7_1*x7_7 + 22*x7_1*x7_8 + 22*x7_1*x7_9 + 176*x7_1*x8_1\n",
      "  + 198*x7_1*x9_1 + 22*x7_1*y_1_capacity_const@int_slack@0\n",
      "  + 44*x7_1*y_1_capacity_const@int_slack@1\n",
      "  + 88*x7_1*y_1_capacity_const@int_slack@2\n",
      "  + 176*x7_1*y_1_capacity_const@int_slack@3 + 220*x7_10*x10_10 + 22*x7_10^2\n",
      "  + 176*x7_10*x8_10 + 198*x7_10*x9_10 + 22*x7_10*y_10_capacity_const@int_slack@0\n",
      "  + 44*x7_10*y_10_capacity_const@int_slack@1\n",
      "  + 88*x7_10*y_10_capacity_const@int_slack@2\n",
      "  + 176*x7_10*y_10_capacity_const@int_slack@3 + 220*x7_2*x10_2 + 22*x7_2*x7_10\n",
      "  + 22*x7_2^2 + 22*x7_2*x7_3 + 22*x7_2*x7_4 + 22*x7_2*x7_5 + 22*x7_2*x7_6\n",
      "  + 22*x7_2*x7_7 + 22*x7_2*x7_8 + 22*x7_2*x7_9 + 176*x7_2*x8_2 + 198*x7_2*x9_2\n",
      "  + 22*x7_2*y_2_capacity_const@int_slack@0\n",
      "  + 44*x7_2*y_2_capacity_const@int_slack@1\n",
      "  + 88*x7_2*y_2_capacity_const@int_slack@2\n",
      "  + 176*x7_2*y_2_capacity_const@int_slack@3 + 220*x7_3*x10_3 + 22*x7_3*x7_10\n",
      "  + 22*x7_3^2 + 22*x7_3*x7_4 + 22*x7_3*x7_5 + 22*x7_3*x7_6 + 22*x7_3*x7_7\n",
      "  + 22*x7_3*x7_8 + 22*x7_3*x7_9 + 176*x7_3*x8_3 + 198*x7_3*x9_3\n",
      "  + 22*x7_3*y_3_capacity_const@int_slack@0\n",
      "  + 44*x7_3*y_3_capacity_const@int_slack@1\n",
      "  + 88*x7_3*y_3_capacity_const@int_slack@2\n",
      "  + 176*x7_3*y_3_capacity_const@int_slack@3 + 220*x7_4*x10_4 + 22*x7_4*x7_10\n",
      "  + 22*x7_4^2 + 22*x7_4*x7_5 + 22*x7_4*x7_6 + 22*x7_4*x7_7 + 22*x7_4*x7_8\n",
      "  + 22*x7_4*x7_9 + 176*x7_4*x8_4 + 198*x7_4*x9_4\n",
      "  + 22*x7_4*y_4_capacity_const@int_slack@0\n",
      "  + 44*x7_4*y_4_capacity_const@int_slack@1\n",
      "  + 88*x7_4*y_4_capacity_const@int_slack@2\n",
      "  + 176*x7_4*y_4_capacity_const@int_slack@3 + 220*x7_5*x10_5 + 22*x7_5*x7_10\n",
      "  + 22*x7_5^2 + 22*x7_5*x7_6 + 22*x7_5*x7_7 + 22*x7_5*x7_8 + 22*x7_5*x7_9\n",
      "  + 176*x7_5*x8_5 + 198*x7_5*x9_5 + 22*x7_5*y_5_capacity_const@int_slack@0\n",
      "  + 44*x7_5*y_5_capacity_const@int_slack@1\n",
      "  + 88*x7_5*y_5_capacity_const@int_slack@2\n",
      "  + 176*x7_5*y_5_capacity_const@int_slack@3 + 220*x7_6*x10_6 + 22*x7_6*x7_10\n",
      "  + 22*x7_6^2 + 22*x7_6*x7_7 + 22*x7_6*x7_8 + 22*x7_6*x7_9 + 176*x7_6*x8_6\n",
      "  + 198*x7_6*x9_6 + 22*x7_6*y_6_capacity_const@int_slack@0\n",
      "  + 44*x7_6*y_6_capacity_const@int_slack@1\n",
      "  + 88*x7_6*y_6_capacity_const@int_slack@2\n",
      "  + 176*x7_6*y_6_capacity_const@int_slack@3 + 220*x7_7*x10_7 + 22*x7_7*x7_10\n",
      "  + 22*x7_7^2 + 22*x7_7*x7_8 + 22*x7_7*x7_9 + 176*x7_7*x8_7 + 198*x7_7*x9_7\n",
      "  + 22*x7_7*y_7_capacity_const@int_slack@0\n",
      "  + 44*x7_7*y_7_capacity_const@int_slack@1\n",
      "  + 88*x7_7*y_7_capacity_const@int_slack@2\n",
      "  + 176*x7_7*y_7_capacity_const@int_slack@3 + 220*x7_8*x10_8 + 22*x7_8*x7_10\n",
      "  + 22*x7_8^2 + 22*x7_8*x7_9 + 176*x7_8*x8_8 + 198*x7_8*x9_8\n",
      "  + 22*x7_8*y_8_capacity_const@int_slack@0\n",
      "  + 44*x7_8*y_8_capacity_const@int_slack@1\n",
      "  + 88*x7_8*y_8_capacity_const@int_slack@2\n",
      "  + 176*x7_8*y_8_capacity_const@int_slack@3 + 220*x7_9*x10_9 + 22*x7_9*x7_10\n",
      "  + 22*x7_9^2 + 176*x7_9*x8_9 + 198*x7_9*x9_9\n",
      "  + 22*x7_9*y_9_capacity_const@int_slack@0\n",
      "  + 44*x7_9*y_9_capacity_const@int_slack@1\n",
      "  + 88*x7_9*y_9_capacity_const@int_slack@2\n",
      "  + 176*x7_9*y_9_capacity_const@int_slack@3 + 1760*x8_1*x10_1 + 715*x8_1^2\n",
      "  + 22*x8_1*x8_10 + 22*x8_1*x8_2 + 22*x8_1*x8_3 + 22*x8_1*x8_4 + 22*x8_1*x8_5\n",
      "  + 22*x8_1*x8_6 + 22*x8_1*x8_7 + 22*x8_1*x8_8 + 22*x8_1*x8_9 + 1584*x8_1*x9_1\n",
      "  + 176*x8_1*y_1_capacity_const@int_slack@0\n",
      "  + 352*x8_1*y_1_capacity_const@int_slack@1\n",
      "  + 704*x8_1*y_1_capacity_const@int_slack@2\n",
      "  + 1408*x8_1*y_1_capacity_const@int_slack@3 + 1760*x8_10*x10_10 + 715*x8_10^2\n",
      "  + 1584*x8_10*x9_10 + 176*x8_10*y_10_capacity_const@int_slack@0\n",
      "  + 352*x8_10*y_10_capacity_const@int_slack@1\n",
      "  + 704*x8_10*y_10_capacity_const@int_slack@2\n",
      "  + 1408*x8_10*y_10_capacity_const@int_slack@3 + 1760*x8_2*x10_2 + 22*x8_2*x8_10\n",
      "  + 715*x8_2^2 + 22*x8_2*x8_3 + 22*x8_2*x8_4 + 22*x8_2*x8_5 + 22*x8_2*x8_6\n",
      "  + 22*x8_2*x8_7 + 22*x8_2*x8_8 + 22*x8_2*x8_9 + 1584*x8_2*x9_2\n",
      "  + 176*x8_2*y_2_capacity_const@int_slack@0\n",
      "  + 352*x8_2*y_2_capacity_const@int_slack@1\n",
      "  + 704*x8_2*y_2_capacity_const@int_slack@2\n",
      "  + 1408*x8_2*y_2_capacity_const@int_slack@3 + 1760*x8_3*x10_3 + 22*x8_3*x8_10\n",
      "  + 715*x8_3^2 + 22*x8_3*x8_4 + 22*x8_3*x8_5 + 22*x8_3*x8_6 + 22*x8_3*x8_7\n",
      "  + 22*x8_3*x8_8 + 22*x8_3*x8_9 + 1584*x8_3*x9_3\n",
      "  + 176*x8_3*y_3_capacity_const@int_slack@0\n",
      "  + 352*x8_3*y_3_capacity_const@int_slack@1\n",
      "  + 704*x8_3*y_3_capacity_const@int_slack@2\n",
      "  + 1408*x8_3*y_3_capacity_const@int_slack@3 + 1760*x8_4*x10_4 + 22*x8_4*x8_10\n",
      "  + 715*x8_4^2 + 22*x8_4*x8_5 + 22*x8_4*x8_6 + 22*x8_4*x8_7 + 22*x8_4*x8_8\n",
      "  + 22*x8_4*x8_9 + 1584*x8_4*x9_4 + 176*x8_4*y_4_capacity_const@int_slack@0\n",
      "  + 352*x8_4*y_4_capacity_const@int_slack@1\n",
      "  + 704*x8_4*y_4_capacity_const@int_slack@2\n",
      "  + 1408*x8_4*y_4_capacity_const@int_slack@3 + 1760*x8_5*x10_5 + 22*x8_5*x8_10\n",
      "  + 715*x8_5^2 + 22*x8_5*x8_6 + 22*x8_5*x8_7 + 22*x8_5*x8_8 + 22*x8_5*x8_9\n",
      "  + 1584*x8_5*x9_5 + 176*x8_5*y_5_capacity_const@int_slack@0\n",
      "  + 352*x8_5*y_5_capacity_const@int_slack@1\n",
      "  + 704*x8_5*y_5_capacity_const@int_slack@2\n",
      "  + 1408*x8_5*y_5_capacity_const@int_slack@3 + 1760*x8_6*x10_6 + 22*x8_6*x8_10\n",
      "  + 715*x8_6^2 + 22*x8_6*x8_7 + 22*x8_6*x8_8 + 22*x8_6*x8_9 + 1584*x8_6*x9_6\n",
      "  + 176*x8_6*y_6_capacity_const@int_slack@0\n",
      "  + 352*x8_6*y_6_capacity_const@int_slack@1\n",
      "  + 704*x8_6*y_6_capacity_const@int_slack@2\n",
      "  + 1408*x8_6*y_6_capacity_const@int_slack@3 + 1760*x8_7*x10_7 + 22*x8_7*x8_10\n",
      "  + 715*x8_7^2 + 22*x8_7*x8_8 + 22*x8_7*x8_9 + 1584*x8_7*x9_7\n",
      "  + 176*x8_7*y_7_capacity_const@int_slack@0\n",
      "  + 352*x8_7*y_7_capacity_const@int_slack@1\n",
      "  + 704*x8_7*y_7_capacity_const@int_slack@2\n",
      "  + 1408*x8_7*y_7_capacity_const@int_slack@3 + 1760*x8_8*x10_8 + 22*x8_8*x8_10\n",
      "  + 715*x8_8^2 + 22*x8_8*x8_9 + 1584*x8_8*x9_8\n",
      "  + 176*x8_8*y_8_capacity_const@int_slack@0\n",
      "  + 352*x8_8*y_8_capacity_const@int_slack@1\n",
      "  + 704*x8_8*y_8_capacity_const@int_slack@2\n",
      "  + 1408*x8_8*y_8_capacity_const@int_slack@3 + 1760*x8_9*x10_9 + 22*x8_9*x8_10\n",
      "  + 715*x8_9^2 + 1584*x8_9*x9_9 + 176*x8_9*y_9_capacity_const@int_slack@0\n",
      "  + 352*x8_9*y_9_capacity_const@int_slack@1\n",
      "  + 704*x8_9*y_9_capacity_const@int_slack@2\n",
      "  + 1408*x8_9*y_9_capacity_const@int_slack@3 + 1980*x9_1*x10_1 + 902*x9_1^2\n",
      "  + 22*x9_1*x9_10 + 22*x9_1*x9_2 + 22*x9_1*x9_3 + 22*x9_1*x9_4 + 22*x9_1*x9_5\n",
      "  + 22*x9_1*x9_6 + 22*x9_1*x9_7 + 22*x9_1*x9_8 + 22*x9_1*x9_9\n",
      "  + 198*x9_1*y_1_capacity_const@int_slack@0\n",
      "  + 396*x9_1*y_1_capacity_const@int_slack@1\n",
      "  + 792*x9_1*y_1_capacity_const@int_slack@2\n",
      "  + 1584*x9_1*y_1_capacity_const@int_slack@3 + 1980*x9_10*x10_10 + 902*x9_10^2\n",
      "  + 198*x9_10*y_10_capacity_const@int_slack@0\n",
      "  + 396*x9_10*y_10_capacity_const@int_slack@1\n",
      "  + 792*x9_10*y_10_capacity_const@int_slack@2\n",
      "  + 1584*x9_10*y_10_capacity_const@int_slack@3 + 1980*x9_2*x10_2 + 22*x9_2*x9_10\n",
      "  + 902*x9_2^2 + 22*x9_2*x9_3 + 22*x9_2*x9_4 + 22*x9_2*x9_5 + 22*x9_2*x9_6\n",
      "  + 22*x9_2*x9_7 + 22*x9_2*x9_8 + 22*x9_2*x9_9\n",
      "  + 198*x9_2*y_2_capacity_const@int_slack@0\n",
      "  + 396*x9_2*y_2_capacity_const@int_slack@1\n",
      "  + 792*x9_2*y_2_capacity_const@int_slack@2\n",
      "  + 1584*x9_2*y_2_capacity_const@int_slack@3 + 1980*x9_3*x10_3 + 22*x9_3*x9_10\n",
      "  + 902*x9_3^2 + 22*x9_3*x9_4 + 22*x9_3*x9_5 + 22*x9_3*x9_6 + 22*x9_3*x9_7\n",
      "  + 22*x9_3*x9_8 + 22*x9_3*x9_9 + 198*x9_3*y_3_capacity_const@int_slack@0\n",
      "  + 396*x9_3*y_3_capacity_const@int_slack@1\n",
      "  + 792*x9_3*y_3_capacity_const@int_slack@2\n",
      "  + 1584*x9_3*y_3_capacity_const@int_slack@3 + 1980*x9_4*x10_4 + 22*x9_4*x9_10\n",
      "  + 902*x9_4^2 + 22*x9_4*x9_5 + 22*x9_4*x9_6 + 22*x9_4*x9_7 + 22*x9_4*x9_8\n",
      "  + 22*x9_4*x9_9 + 198*x9_4*y_4_capacity_const@int_slack@0\n",
      "  + 396*x9_4*y_4_capacity_const@int_slack@1\n",
      "  + 792*x9_4*y_4_capacity_const@int_slack@2\n",
      "  + 1584*x9_4*y_4_capacity_const@int_slack@3 + 1980*x9_5*x10_5 + 22*x9_5*x9_10\n",
      "  + 902*x9_5^2 + 22*x9_5*x9_6 + 22*x9_5*x9_7 + 22*x9_5*x9_8 + 22*x9_5*x9_9\n",
      "  + 198*x9_5*y_5_capacity_const@int_slack@0\n",
      "  + 396*x9_5*y_5_capacity_const@int_slack@1\n",
      "  + 792*x9_5*y_5_capacity_const@int_slack@2\n",
      "  + 1584*x9_5*y_5_capacity_const@int_slack@3 + 1980*x9_6*x10_6 + 22*x9_6*x9_10\n",
      "  + 902*x9_6^2 + 22*x9_6*x9_7 + 22*x9_6*x9_8 + 22*x9_6*x9_9\n",
      "  + 198*x9_6*y_6_capacity_const@int_slack@0\n",
      "  + 396*x9_6*y_6_capacity_const@int_slack@1\n",
      "  + 792*x9_6*y_6_capacity_const@int_slack@2\n",
      "  + 1584*x9_6*y_6_capacity_const@int_slack@3 + 1980*x9_7*x10_7 + 22*x9_7*x9_10\n",
      "  + 902*x9_7^2 + 22*x9_7*x9_8 + 22*x9_7*x9_9\n",
      "  + 198*x9_7*y_7_capacity_const@int_slack@0\n",
      "  + 396*x9_7*y_7_capacity_const@int_slack@1\n",
      "  + 792*x9_7*y_7_capacity_const@int_slack@2\n",
      "  + 1584*x9_7*y_7_capacity_const@int_slack@3 + 1980*x9_8*x10_8 + 22*x9_8*x9_10\n",
      "  + 902*x9_8^2 + 22*x9_8*x9_9 + 198*x9_8*y_8_capacity_const@int_slack@0\n",
      "  + 396*x9_8*y_8_capacity_const@int_slack@1\n",
      "  + 792*x9_8*y_8_capacity_const@int_slack@2\n",
      "  + 1584*x9_8*y_8_capacity_const@int_slack@3 + 1980*x9_9*x10_9 + 22*x9_9*x9_10\n",
      "  + 902*x9_9^2 + 198*x9_9*y_9_capacity_const@int_slack@0\n",
      "  + 396*x9_9*y_9_capacity_const@int_slack@1\n",
      "  + 792*x9_9*y_9_capacity_const@int_slack@2\n",
      "  + 1584*x9_9*y_9_capacity_const@int_slack@3 - 3300*y1*x10_1 - 990*y1*x1_1\n",
      "  - 660*y1*x2_1 - 1650*y1*x3_1 - 1320*y1*x4_1 - 2310*y1*x5_1 - 1980*y1*x6_1\n",
      "  - 330*y1*x7_1 - 2640*y1*x8_1 - 2970*y1*x9_1 + 2475*y1^2\n",
      "  - 330*y1*y_1_capacity_const@int_slack@0\n",
      "  - 660*y1*y_1_capacity_const@int_slack@1\n",
      "  - 1320*y1*y_1_capacity_const@int_slack@2\n",
      "  - 2640*y1*y_1_capacity_const@int_slack@3 - 3300*y10*x10_10 - 990*y10*x1_10\n",
      "  - 660*y10*x2_10 - 1650*y10*x3_10 - 1320*y10*x4_10 - 2310*y10*x5_10\n",
      "  - 1980*y10*x6_10 - 330*y10*x7_10 - 2640*y10*x8_10 - 2970*y10*x9_10\n",
      "  + 2475*y10^2 - 330*y10*y_10_capacity_const@int_slack@0\n",
      "  - 660*y10*y_10_capacity_const@int_slack@1\n",
      "  - 1320*y10*y_10_capacity_const@int_slack@2\n",
      "  - 2640*y10*y_10_capacity_const@int_slack@3 - 3300*y2*x10_2 - 990*y2*x1_2\n",
      "  - 660*y2*x2_2 - 1650*y2*x3_2 - 1320*y2*x4_2 - 2310*y2*x5_2 - 1980*y2*x6_2\n",
      "  - 330*y2*x7_2 - 2640*y2*x8_2 - 2970*y2*x9_2 + 2475*y2^2\n",
      "  - 330*y2*y_2_capacity_const@int_slack@0\n",
      "  - 660*y2*y_2_capacity_const@int_slack@1\n",
      "  - 1320*y2*y_2_capacity_const@int_slack@2\n",
      "  - 2640*y2*y_2_capacity_const@int_slack@3 - 3300*y3*x10_3 - 990*y3*x1_3\n",
      "  - 660*y3*x2_3 - 1650*y3*x3_3 - 1320*y3*x4_3 - 2310*y3*x5_3 - 1980*y3*x6_3\n",
      "  - 330*y3*x7_3 - 2640*y3*x8_3 - 2970*y3*x9_3 + 2475*y3^2\n",
      "  - 330*y3*y_3_capacity_const@int_slack@0\n",
      "  - 660*y3*y_3_capacity_const@int_slack@1\n",
      "  - 1320*y3*y_3_capacity_const@int_slack@2\n",
      "  - 2640*y3*y_3_capacity_const@int_slack@3 - 3300*y4*x10_4 - 990*y4*x1_4\n",
      "  - 660*y4*x2_4 - 1650*y4*x3_4 - 1320*y4*x4_4 - 2310*y4*x5_4 - 1980*y4*x6_4\n",
      "  - 330*y4*x7_4 - 2640*y4*x8_4 - 2970*y4*x9_4 + 2475*y4^2\n",
      "  - 330*y4*y_4_capacity_const@int_slack@0\n",
      "  - 660*y4*y_4_capacity_const@int_slack@1\n",
      "  - 1320*y4*y_4_capacity_const@int_slack@2\n",
      "  - 2640*y4*y_4_capacity_const@int_slack@3 - 3300*y5*x10_5 - 990*y5*x1_5\n",
      "  - 660*y5*x2_5 - 1650*y5*x3_5 - 1320*y5*x4_5 - 2310*y5*x5_5 - 1980*y5*x6_5\n",
      "  - 330*y5*x7_5 - 2640*y5*x8_5 - 2970*y5*x9_5 + 2475*y5^2\n",
      "  - 330*y5*y_5_capacity_const@int_slack@0\n",
      "  - 660*y5*y_5_capacity_const@int_slack@1\n",
      "  - 1320*y5*y_5_capacity_const@int_slack@2\n",
      "  - 2640*y5*y_5_capacity_const@int_slack@3 - 3300*y6*x10_6 - 990*y6*x1_6\n",
      "  - 660*y6*x2_6 - 1650*y6*x3_6 - 1320*y6*x4_6 - 2310*y6*x5_6 - 1980*y6*x6_6\n",
      "  - 330*y6*x7_6 - 2640*y6*x8_6 - 2970*y6*x9_6 + 2475*y6^2\n",
      "  - 330*y6*y_6_capacity_const@int_slack@0\n",
      "  - 660*y6*y_6_capacity_const@int_slack@1\n",
      "  - 1320*y6*y_6_capacity_const@int_slack@2\n",
      "  - 2640*y6*y_6_capacity_const@int_slack@3 - 3300*y7*x10_7 - 990*y7*x1_7\n",
      "  - 660*y7*x2_7 - 1650*y7*x3_7 - 1320*y7*x4_7 - 2310*y7*x5_7 - 1980*y7*x6_7\n",
      "  - 330*y7*x7_7 - 2640*y7*x8_7 - 2970*y7*x9_7 + 2475*y7^2\n",
      "  - 330*y7*y_7_capacity_const@int_slack@0\n",
      "  - 660*y7*y_7_capacity_const@int_slack@1\n",
      "  - 1320*y7*y_7_capacity_const@int_slack@2\n",
      "  - 2640*y7*y_7_capacity_const@int_slack@3 - 3300*y8*x10_8 - 990*y8*x1_8\n",
      "  - 660*y8*x2_8 - 1650*y8*x3_8 - 1320*y8*x4_8 - 2310*y8*x5_8 - 1980*y8*x6_8\n",
      "  - 330*y8*x7_8 - 2640*y8*x8_8 - 2970*y8*x9_8 + 2475*y8^2\n",
      "  - 330*y8*y_8_capacity_const@int_slack@0\n",
      "  - 660*y8*y_8_capacity_const@int_slack@1\n",
      "  - 1320*y8*y_8_capacity_const@int_slack@2\n",
      "  - 2640*y8*y_8_capacity_const@int_slack@3 - 3300*y9*x10_9 - 990*y9*x1_9\n",
      "  - 660*y9*x2_9 - 1650*y9*x3_9 - 1320*y9*x4_9 - 2310*y9*x5_9 - 1980*y9*x6_9\n",
      "  - 330*y9*x7_9 - 2640*y9*x8_9 - 2970*y9*x9_9 + 2475*y9^2\n",
      "  - 330*y9*y_9_capacity_const@int_slack@0\n",
      "  - 660*y9*y_9_capacity_const@int_slack@1\n",
      "  - 1320*y9*y_9_capacity_const@int_slack@2\n",
      "  - 2640*y9*y_9_capacity_const@int_slack@3\n",
      "  + 11*y_10_capacity_const@int_slack@0^2\n",
      "  + 44*y_10_capacity_const@int_slack@0*y_10_capacity_const@int_slack@1\n",
      "  + 88*y_10_capacity_const@int_slack@0*y_10_capacity_const@int_slack@2\n",
      "  + 176*y_10_capacity_const@int_slack@0*y_10_capacity_const@int_slack@3\n",
      "  + 44*y_10_capacity_const@int_slack@1^2\n",
      "  + 176*y_10_capacity_const@int_slack@1*y_10_capacity_const@int_slack@2\n",
      "  + 352*y_10_capacity_const@int_slack@1*y_10_capacity_const@int_slack@3\n",
      "  + 176*y_10_capacity_const@int_slack@2^2\n",
      "  + 704*y_10_capacity_const@int_slack@2*y_10_capacity_const@int_slack@3\n",
      "  + 704*y_10_capacity_const@int_slack@3^2 + 11*y_1_capacity_const@int_slack@0^2\n",
      "  + 44*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@1\n",
      "  + 88*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@2\n",
      "  + 176*y_1_capacity_const@int_slack@0*y_1_capacity_const@int_slack@3\n",
      "  + 44*y_1_capacity_const@int_slack@1^2\n",
      "  + 176*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@2\n",
      "  + 352*y_1_capacity_const@int_slack@1*y_1_capacity_const@int_slack@3\n",
      "  + 176*y_1_capacity_const@int_slack@2^2\n",
      "  + 704*y_1_capacity_const@int_slack@2*y_1_capacity_const@int_slack@3\n",
      "  + 704*y_1_capacity_const@int_slack@3^2 + 11*y_2_capacity_const@int_slack@0^2\n",
      "  + 44*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@1\n",
      "  + 88*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@2\n",
      "  + 176*y_2_capacity_const@int_slack@0*y_2_capacity_const@int_slack@3\n",
      "  + 44*y_2_capacity_const@int_slack@1^2\n",
      "  + 176*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@2\n",
      "  + 352*y_2_capacity_const@int_slack@1*y_2_capacity_const@int_slack@3\n",
      "  + 176*y_2_capacity_const@int_slack@2^2\n",
      "  + 704*y_2_capacity_const@int_slack@2*y_2_capacity_const@int_slack@3\n",
      "  + 704*y_2_capacity_const@int_slack@3^2 + 11*y_3_capacity_const@int_slack@0^2\n",
      "  + 44*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@1\n",
      "  + 88*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@2\n",
      "  + 176*y_3_capacity_const@int_slack@0*y_3_capacity_const@int_slack@3\n",
      "  + 44*y_3_capacity_const@int_slack@1^2\n",
      "  + 176*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@2\n",
      "  + 352*y_3_capacity_const@int_slack@1*y_3_capacity_const@int_slack@3\n",
      "  + 176*y_3_capacity_const@int_slack@2^2\n",
      "  + 704*y_3_capacity_const@int_slack@2*y_3_capacity_const@int_slack@3\n",
      "  + 704*y_3_capacity_const@int_slack@3^2 + 11*y_4_capacity_const@int_slack@0^2\n",
      "  + 44*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@1\n",
      "  + 88*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@2\n",
      "  + 176*y_4_capacity_const@int_slack@0*y_4_capacity_const@int_slack@3\n",
      "  + 44*y_4_capacity_const@int_slack@1^2\n",
      "  + 176*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@2\n",
      "  + 352*y_4_capacity_const@int_slack@1*y_4_capacity_const@int_slack@3\n",
      "  + 176*y_4_capacity_const@int_slack@2^2\n",
      "  + 704*y_4_capacity_const@int_slack@2*y_4_capacity_const@int_slack@3\n",
      "  + 704*y_4_capacity_const@int_slack@3^2 + 11*y_5_capacity_const@int_slack@0^2\n",
      "  + 44*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@1\n",
      "  + 88*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@2\n",
      "  + 176*y_5_capacity_const@int_slack@0*y_5_capacity_const@int_slack@3\n",
      "  + 44*y_5_capacity_const@int_slack@1^2\n",
      "  + 176*y_5_capacity_const@int_slack@1*y_5_capacity_const@int_slack@2\n",
      "  + 352*y_5_capacity_const@int_slack@1*y_5_capacity_const@int_slack@3\n",
      "  + 176*y_5_capacity_const@int_slack@2^2\n",
      "  + 704*y_5_capacity_const@int_slack@2*y_5_capacity_const@int_slack@3\n",
      "  + 704*y_5_capacity_const@int_slack@3^2 + 11*y_6_capacity_const@int_slack@0^2\n",
      "  + 44*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@1\n",
      "  + 88*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@2\n",
      "  + 176*y_6_capacity_const@int_slack@0*y_6_capacity_const@int_slack@3\n",
      "  + 44*y_6_capacity_const@int_slack@1^2\n",
      "  + 176*y_6_capacity_const@int_slack@1*y_6_capacity_const@int_slack@2\n",
      "  + 352*y_6_capacity_const@int_slack@1*y_6_capacity_const@int_slack@3\n",
      "  + 176*y_6_capacity_const@int_slack@2^2\n",
      "  + 704*y_6_capacity_const@int_slack@2*y_6_capacity_const@int_slack@3\n",
      "  + 704*y_6_capacity_const@int_slack@3^2 + 11*y_7_capacity_const@int_slack@0^2\n",
      "  + 44*y_7_capacity_const@int_slack@0*y_7_capacity_const@int_slack@1\n",
      "  + 88*y_7_capacity_const@int_slack@0*y_7_capacity_const@int_slack@2\n",
      "  + 176*y_7_capacity_const@int_slack@0*y_7_capacity_const@int_slack@3\n",
      "  + 44*y_7_capacity_const@int_slack@1^2\n",
      "  + 176*y_7_capacity_const@int_slack@1*y_7_capacity_const@int_slack@2\n",
      "  + 352*y_7_capacity_const@int_slack@1*y_7_capacity_const@int_slack@3\n",
      "  + 176*y_7_capacity_const@int_slack@2^2\n",
      "  + 704*y_7_capacity_const@int_slack@2*y_7_capacity_const@int_slack@3\n",
      "  + 704*y_7_capacity_const@int_slack@3^2 + 11*y_8_capacity_const@int_slack@0^2\n",
      "  + 44*y_8_capacity_const@int_slack@0*y_8_capacity_const@int_slack@1\n",
      "  + 88*y_8_capacity_const@int_slack@0*y_8_capacity_const@int_slack@2\n",
      "  + 176*y_8_capacity_const@int_slack@0*y_8_capacity_const@int_slack@3\n",
      "  + 44*y_8_capacity_const@int_slack@1^2\n",
      "  + 176*y_8_capacity_const@int_slack@1*y_8_capacity_const@int_slack@2\n",
      "  + 352*y_8_capacity_const@int_slack@1*y_8_capacity_const@int_slack@3\n",
      "  + 176*y_8_capacity_const@int_slack@2^2\n",
      "  + 704*y_8_capacity_const@int_slack@2*y_8_capacity_const@int_slack@3\n",
      "  + 704*y_8_capacity_const@int_slack@3^2 + 11*y_9_capacity_const@int_slack@0^2\n",
      "  + 44*y_9_capacity_const@int_slack@0*y_9_capacity_const@int_slack@1\n",
      "  + 88*y_9_capacity_const@int_slack@0*y_9_capacity_const@int_slack@2\n",
      "  + 176*y_9_capacity_const@int_slack@0*y_9_capacity_const@int_slack@3\n",
      "  + 44*y_9_capacity_const@int_slack@1^2\n",
      "  + 176*y_9_capacity_const@int_slack@1*y_9_capacity_const@int_slack@2\n",
      "  + 352*y_9_capacity_const@int_slack@1*y_9_capacity_const@int_slack@3\n",
      "  + 176*y_9_capacity_const@int_slack@2^2\n",
      "  + 704*y_9_capacity_const@int_slack@2*y_9_capacity_const@int_slack@3\n",
      "  + 704*y_9_capacity_const@int_slack@3^2 - 22*x10_1 - 22*x10_10 - 22*x10_2\n",
      "  - 22*x10_3 - 22*x10_4 - 22*x10_5 - 22*x10_6 - 22*x10_7 - 22*x10_8 - 22*x10_9\n",
      "  - 22*x1_1 - 22*x1_10 - 22*x1_2 - 22*x1_3 - 22*x1_4 - 22*x1_5 - 22*x1_6\n",
      "  - 22*x1_7 - 22*x1_8 - 22*x1_9 - 22*x2_1 - 22*x2_10 - 22*x2_2 - 22*x2_3\n",
      "  - 22*x2_4 - 22*x2_5 - 22*x2_6 - 22*x2_7 - 22*x2_8 - 22*x2_9 - 22*x3_1\n",
      "  - 22*x3_10 - 22*x3_2 - 22*x3_3 - 22*x3_4 - 22*x3_5 - 22*x3_6 - 22*x3_7\n",
      "  - 22*x3_8 - 22*x3_9 - 22*x4_1 - 22*x4_10 - 22*x4_2 - 22*x4_3 - 22*x4_4\n",
      "  - 22*x4_5 - 22*x4_6 - 22*x4_7 - 22*x4_8 - 22*x4_9 - 22*x5_1 - 22*x5_10\n",
      "  - 22*x5_2 - 22*x5_3 - 22*x5_4 - 22*x5_5 - 22*x5_6 - 22*x5_7 - 22*x5_8\n",
      "  - 22*x5_9 - 22*x6_1 - 22*x6_10 - 22*x6_2 - 22*x6_3 - 22*x6_4 - 22*x6_5\n",
      "  - 22*x6_6 - 22*x6_7 - 22*x6_8 - 22*x6_9 - 22*x7_1 - 22*x7_10 - 22*x7_2\n",
      "  - 22*x7_3 - 22*x7_4 - 22*x7_5 - 22*x7_6 - 22*x7_7 - 22*x7_8 - 22*x7_9\n",
      "  - 22*x8_1 - 22*x8_10 - 22*x8_2 - 22*x8_3 - 22*x8_4 - 22*x8_5 - 22*x8_6\n",
      "  - 22*x8_7 - 22*x8_8 - 22*x8_9 - 22*x9_1 - 22*x9_10 - 22*x9_2 - 22*x9_3\n",
      "  - 22*x9_4 - 22*x9_5 - 22*x9_6 - 22*x9_7 - 22*x9_8 - 22*x9_9 + y1 + y10 + y2\n",
      "  + y3 + y4 + y5 + y6 + y7 + y8 + y9 + 110\n",
      "\n",
      "Subject to\n",
      "  No constraints\n",
      "\n",
      "  Binary variables (150)\n",
      "    y1 y2 y3 y4 y5 y6 y7 y8 y9 y10 x1_1 x1_2 x1_3 x1_4 x1_5 x1_6 x1_7 x1_8 x1_9\n",
      "    x1_10 x2_1 x2_2 x2_3 x2_4 x2_5 x2_6 x2_7 x2_8 x2_9 x2_10 x3_1 x3_2 x3_3 x3_4\n",
      "    x3_5 x3_6 x3_7 x3_8 x3_9 x3_10 x4_1 x4_2 x4_3 x4_4 x4_5 x4_6 x4_7 x4_8 x4_9\n",
      "    x4_10 x5_1 x5_2 x5_3 x5_4 x5_5 x5_6 x5_7 x5_8 x5_9 x5_10 x6_1 x6_2 x6_3 x6_4\n",
      "    x6_5 x6_6 x6_7 x6_8 x6_9 x6_10 x7_1 x7_2 x7_3 x7_4 x7_5 x7_6 x7_7 x7_8 x7_9\n",
      "    x7_10 x8_1 x8_2 x8_3 x8_4 x8_5 x8_6 x8_7 x8_8 x8_9 x8_10 x9_1 x9_2 x9_3 x9_4\n",
      "    x9_5 x9_6 x9_7 x9_8 x9_9 x9_10 x10_1 x10_2 x10_3 x10_4 x10_5 x10_6 x10_7\n",
      "    x10_8 x10_9 x10_10 y_1_capacity_const@int_slack@0\n",
      "    y_1_capacity_const@int_slack@1 y_1_capacity_const@int_slack@2\n",
      "    y_1_capacity_const@int_slack@3 y_2_capacity_const@int_slack@0\n",
      "    y_2_capacity_const@int_slack@1 y_2_capacity_const@int_slack@2\n",
      "    y_2_capacity_const@int_slack@3 y_3_capacity_const@int_slack@0\n",
      "    y_3_capacity_const@int_slack@1 y_3_capacity_const@int_slack@2\n",
      "    y_3_capacity_const@int_slack@3 y_4_capacity_const@int_slack@0\n",
      "    y_4_capacity_const@int_slack@1 y_4_capacity_const@int_slack@2\n",
      "    y_4_capacity_const@int_slack@3 y_5_capacity_const@int_slack@0\n",
      "    y_5_capacity_const@int_slack@1 y_5_capacity_const@int_slack@2\n",
      "    y_5_capacity_const@int_slack@3 y_6_capacity_const@int_slack@0\n",
      "    y_6_capacity_const@int_slack@1 y_6_capacity_const@int_slack@2\n",
      "    y_6_capacity_const@int_slack@3 y_7_capacity_const@int_slack@0\n",
      "    y_7_capacity_const@int_slack@1 y_7_capacity_const@int_slack@2\n",
      "    y_7_capacity_const@int_slack@3 y_8_capacity_const@int_slack@0\n",
      "    y_8_capacity_const@int_slack@1 y_8_capacity_const@int_slack@2\n",
      "    y_8_capacity_const@int_slack@3 y_9_capacity_const@int_slack@0\n",
      "    y_9_capacity_const@int_slack@1 y_9_capacity_const@int_slack@2\n",
      "    y_9_capacity_const@int_slack@3 y_10_capacity_const@int_slack@0\n",
      "    y_10_capacity_const@int_slack@1 y_10_capacity_const@int_slack@2\n",
      "    y_10_capacity_const@int_slack@3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sizes = [3, 2, 5, 4, 7, 6, 1, 8, 9, 10]\n",
    "bin_capacity = 15\n",
    "\n",
    "model_ilp_large = BPP_ILP_Program(sizes, bin_capacity)\n",
    "print(\"ILP VERSION\",model_ilp_large.prettyprint())\n",
    "\n",
    "qubo_problem_large = quadratic_program_to_qubo(model_ilp_large)\n",
    "\n",
    "print(\"QUBO VERSION\",qubo_problem.prettyprint())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Create a Brute Force solver for the QUBO problem and solve the specific instances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dwave(object_sizes, container_capacity):\n",
    "    num_objects = len(object_sizes)  # Number of objects\n",
    "    max_containers = num_objects  # Maximum number of containers (can have up to num_objects containers)\n",
    "\n",
    "    # Create a binary quadratic model (BQM)\n",
    "    bqm = BQM(\"BINARY\")\n",
    "    l1 = 5  # Lagrange multiplier\n",
    "\n",
    "    # Add linear terms for containers (minimize the number of containers used)\n",
    "    for container in range(max_containers):\n",
    "        container_var = f\"y_{container}\"  # Variable to indicate if the container is in use\n",
    "        bqm.add_linear(container_var, 1)\n",
    "\n",
    "    # Add constraints: each object must be placed in exactly one container\n",
    "    for obj in range(num_objects):\n",
    "        constraint_one = [(f\"x_{obj}_{container}\", 1) for container in range(max_containers)]  # Coefficients list\n",
    "        bqm.add_linear_equality_constraint(constraint_one, constant=-1, lagrange_multiplier=l1)\n",
    "\n",
    "    # Add capacity constraints: total size of objects in a container should not exceed the container's capacity\n",
    "    for container in range(max_containers):\n",
    "        constraint_two = [(f\"x_{obj}_{container}\", object_sizes[obj]) for obj in range(num_objects)]\n",
    "        constraint_two.append((f\"y_{container}\", -container_capacity))\n",
    "        bqm.add_linear_inequality_constraint(constraint_two, label=f\"y_{container} constraint\", ub=0, lagrange_multiplier=l1)\n",
    "\n",
    "    return bqm\n",
    "\n",
    "def get_QUBO_matrix(bqm):\n",
    "    # Convert BQM to QUBO representation\n",
    "    qubo, offset = bqm.to_qubo()\n",
    "\n",
    "    # Get all variables from QUBO\n",
    "    variables = list(bqm.variables)\n",
    "\n",
    "    # Create a mapping of variables to indices\n",
    "    variable_index = {var: idx for idx, var in enumerate(variables)}\n",
    "\n",
    "    # Initialize the QUBO matrix with zeros\n",
    "    n = len(variables)\n",
    "    qubo_matrix = np.zeros((n, n))\n",
    "\n",
    "    # Fill in the QUBO matrix using the terms from the QUBO representation\n",
    "    for (var1, var2), bias in qubo.items():\n",
    "        i, j = variable_index[var1], variable_index[var2]\n",
    "        qubo_matrix[i, j] = bias\n",
    "\n",
    "    return qubo_matrix, offset, variables\n",
    "\n",
    "def solve_qubo_brute_force(Q):\n",
    "    # Number of variables (from the QUBO matrix size)\n",
    "    n = Q.shape[0]\n",
    "    \n",
    "    # Generate all binary combinations of length n\n",
    "    possible_solutions = list(itertools.product([0, 1], repeat=n))\n",
    "    \n",
    "    # Initialize variables to store the best solution and minimum value\n",
    "    best_solution = None\n",
    "    min_value = float('inf')\n",
    "    \n",
    "    # Loop through all possible binary vectors x\n",
    "    for x in possible_solutions:\n",
    "        # Convert x to a column vector\n",
    "        x_vec = np.array(x).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate the objective function value: x^T Q x\n",
    "        value = np.dot(np.dot(x_vec.T, Q), x_vec)[0, 0]\n",
    "        \n",
    "        # If this is the best value so far, store it\n",
    "        if value < min_value:\n",
    "            min_value = value\n",
    "            best_solution = x\n",
    "    \n",
    "    # Return the best solution and its objective function value\n",
    "    return best_solution, min_value\n",
    "\n",
    "def summarize_solution(solution, object_sizes, container_capacity):\n",
    "    used_containers = []\n",
    "    unused_containers = []\n",
    "    object_placement = {}\n",
    "\n",
    "    # Iterate through the solution to find container and object placements\n",
    "    for var, value in solution:\n",
    "        if var.startswith('y_'):\n",
    "            container_index = int(var.split('_')[1])\n",
    "            if value == 1:\n",
    "                used_containers.append(container_index)\n",
    "            else:\n",
    "                unused_containers.append(container_index)\n",
    "        \n",
    "        elif var.startswith('x_') and value == 1:\n",
    "            # Object is placed in a container\n",
    "            obj_index, container_index = map(int, var.split('_')[1:])\n",
    "            if container_index not in object_placement:\n",
    "                object_placement[container_index] = []\n",
    "            object_placement[container_index].append(obj_index)\n",
    "\n",
    "    # Sort the containers for better presentation\n",
    "    used_containers.sort()\n",
    "    unused_containers.sort()\n",
    "\n",
    "    # Print a summary of the solution\n",
    "    print(f\"Container capacity: {container_capacity}\")\n",
    "    print(f\"Object sizes: {object_sizes}\")\n",
    "    print(f\"Number of containers used: {len(used_containers)}\")\n",
    "    print(f\"Containers used: {used_containers}\")\n",
    "    \n",
    "    if unused_containers:\n",
    "        print(f\"Containers not used: {unused_containers}\")\n",
    "    else:\n",
    "        print(\"All containers were used.\")\n",
    "    \n",
    "    print(\"\\nObject placements and load:\")\n",
    "    for container in used_containers:\n",
    "        objects_in_container = object_placement.get(container, [])\n",
    "        total_weight = sum(object_sizes[obj] for obj in objects_in_container)\n",
    "        print(f\"  Container {container}: Objects {objects_in_container}, Total weight: {total_weight}/{container_capacity}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    total_objects = sum(len(obj_list) for obj_list in object_placement.values())\n",
    "    print(f\"Total number of objects: {total_objects}\")\n",
    "    print(f\"Total weight distributed: {sum(object_sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solution of example using brute force**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector solutions: [('y_0', 0), ('y_1', 1), ('y_2', 1), ('x_0_0', 0), ('x_0_1', 0), ('x_0_2', 1), ('x_1_0', 0), ('x_1_1', 1), ('x_1_2', 0), ('x_2_0', 0), ('x_2_1', 0), ('x_2_2', 1), ('slack_y_0 constraint_0', 0), ('slack_y_0 constraint_1', 0), ('slack_y_0 constraint_2', 0), ('slack_y_1 constraint_0', 0), ('slack_y_1 constraint_1', 0), ('slack_y_1 constraint_2', 1), ('slack_y_2 constraint_0', 0), ('slack_y_2 constraint_1', 0), ('slack_y_2 constraint_2', 0)]\n",
      "Min value: -13.0\n"
     ]
    }
   ],
   "source": [
    "# Problem parameters\n",
    "sizes = [4, 3, 1]  # Sizes of the objects\n",
    "bin_capacity = 5  # Capacity of the containers\n",
    "\n",
    "# Generate the BQM for the problem\n",
    "bqm = model_dwave(sizes, bin_capacity)\n",
    "\n",
    "# Create the QUBO matrix\n",
    "qubo_matrix, variables = get_QUBO_matrix(bqm)\n",
    "\n",
    "# Solve the QUBO matrix\n",
    "best_solution, min_value = solve_qubo_brute_force(qubo_matrix)\n",
    "\n",
    "solution = [ (var,value) for var,value in zip(variables, best_solution)]\n",
    "\n",
    "\n",
    "print(\"Vector solutions:\", solution)\n",
    "print(\"Min value:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 126.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,  126.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,    0.,  126.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [-200.,    0.,    0.,   75.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0., -200.,    0.,   10.,   75.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,    0., -200.,   10.,   10.,   75.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [-150.,    0.,    0.,  120.,    0.,    0.,   40.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0., -150.,    0.,    0.,  120.,    0.,   10.,   40.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,    0., -150.,    0.,    0.,  120.,   10.,   10.,   40.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [ -50.,    0.,    0.,   40.,    0.,    0.,   30.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,  -50.,    0.,    0.,   40.,    0.,    0.,   30.,    0.,\n",
       "          10.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,    0.,  -50.,    0.,    0.,   40.,    0.,    0.,   30.,\n",
       "          10.,   10.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [ -50.,    0.,    0.,   40.,    0.,    0.,   30.,    0.,    0.,\n",
       "          10.,    0.,    0.,    5.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [-100.,    0.,    0.,   80.,    0.,    0.,   60.,    0.,    0.,\n",
       "          20.,    0.,    0.,   20.,   20.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [-100.,    0.,    0.,   80.,    0.,    0.,   60.,    0.,    0.,\n",
       "          20.,    0.,    0.,   20.,   40.,   20.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,  -50.,    0.,    0.,   40.,    0.,    0.,   30.,    0.,\n",
       "           0.,   10.,    0.,    0.,    0.,    0.,    5.,    0.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0., -100.,    0.,    0.,   80.,    0.,    0.,   60.,    0.,\n",
       "           0.,   20.,    0.,    0.,    0.,    0.,   20.,   20.,    0.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0., -100.,    0.,    0.,   80.,    0.,    0.,   60.,    0.,\n",
       "           0.,   20.,    0.,    0.,    0.,    0.,   20.,   40.,   20.,\n",
       "           0.,    0.,    0.],\n",
       "       [   0.,    0.,  -50.,    0.,    0.,   40.,    0.,    0.,   30.,\n",
       "           0.,    0.,   10.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           5.,    0.,    0.],\n",
       "       [   0.,    0., -100.,    0.,    0.,   80.,    0.,    0.,   60.,\n",
       "           0.,    0.,   20.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          20.,   20.,    0.],\n",
       "       [   0.,    0., -100.,    0.,    0.,   80.,    0.,    0.,   60.,\n",
       "           0.,    0.,   20.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          20.,   40.,   20.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qubo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container capacity: 5\n",
      "Object sizes: [4, 3, 1]\n",
      "Number of containers used: 2\n",
      "Containers used: [1, 2]\n",
      "Containers not used: [0]\n",
      "\n",
      "Object placements and load:\n",
      "  Container 1: Objects [1], Total weight: 3/5\n",
      "  Container 2: Objects [0, 2], Total weight: 5/5\n",
      "\n",
      "Summary:\n",
      "Total number of objects: 3\n",
      "Total weight distributed: 8\n"
     ]
    }
   ],
   "source": [
    "summarize_solution(solution, sizes, bin_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. To solve the QUBO, use quantum annealing simulators.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector solutions: [('slack_y_0 constraint_0', 0), ('slack_y_0 constraint_1', 0), ('slack_y_0 constraint_2', 0), ('slack_y_1 constraint_0', 0), ('slack_y_1 constraint_1', 0), ('slack_y_1 constraint_2', 1), ('slack_y_2 constraint_0', 0), ('slack_y_2 constraint_1', 0), ('slack_y_2 constraint_2', 0), ('x_0_0', 0), ('x_0_1', 0), ('x_0_2', 1), ('x_1_0', 0), ('x_1_1', 1), ('x_1_2', 0), ('x_2_0', 0), ('x_2_1', 0), ('x_2_2', 1), ('y_0', 0), ('y_1', 1), ('y_2', 1)]\n",
      "Min value: -13.0\n"
     ]
    }
   ],
   "source": [
    "def solve_qubo_by_annealing(bqm):\n",
    "    sampler = EmbeddingComposite(DWaveSampler(token = api_key))\n",
    "    Q, offset = bqm.to_qubo()\n",
    "    # Solve the QUBO problem using quantum annealing\n",
    "    sampleset = sampler.sample_qubo(Q, num_reads=1000) \n",
    "    return sampleset\n",
    "\n",
    "sampleset = solve_qubo_by_annealing(bqm)\n",
    "best_solution = sampleset.first.sample\n",
    "min_value = sampleset.first.energy\n",
    "\n",
    "solution = list(best_solution.items())\n",
    "print(\"Vector solutions:\", solution)\n",
    "print(\"Min value:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(best_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container capacity: 5\n",
      "Object sizes: [4, 3, 1]\n",
      "Number of containers used: 2\n",
      "Containers used: [1, 2]\n",
      "Containers not used: [0]\n",
      "\n",
      "Object placements and load:\n",
      "  Container 1: Objects [1], Total weight: 3/5\n",
      "  Container 2: Objects [0, 2], Total weight: 5/5\n",
      "\n",
      "Summary:\n",
      "Total number of objects: 3\n",
      "Total weight distributed: 8\n"
     ]
    }
   ],
   "source": [
    "summarize_solution(solution, sizes, bin_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Use a Quantum Variational approach to solve the QUBO.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import autograd.numpy as np2\n",
    "import pennylane as qml\n",
    "\n",
    "Q = qubo_matrix\n",
    "n_wires = Q.shape[0]\n",
    "dev = qml.device('default.qubit', wires=n_wires)\n",
    "\n",
    "def run_an_experiment(optimizer, weights, steps=100, rotation = qml.RX):\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(weights):\n",
    "        qml.BasicEntanglerLayers(weights=weights, wires=range(n_wires), rotation=rotation)\n",
    "        return qml.numpy.array([qml.expval(qml.Z(i)) for i in range(n_wires)])\n",
    "    \n",
    "    def qubo_cost_function(expectation):\n",
    "        binary_solution = ( np2.tanh(expectation) + 1 ) / 2\n",
    "        return np.dot(binary_solution.T, np.dot(Q, binary_solution))\n",
    "\n",
    "    def cost(weights):\n",
    "        expectation = circuit(weights) \n",
    "        energy = qubo_cost_function(expectation)\n",
    "        return energy\n",
    "\n",
    "\n",
    "    params = weights.copy()\n",
    "\n",
    "    for step in range(steps):\n",
    "        params, energy = optimizer.step_and_cost(cost, params)\n",
    "        final_expectation = circuit(params)\n",
    "        qubo_solution = ( np.sign(final_expectation) + 1 ) / 2\n",
    "        print(f\"STEP {step + 1}: {energy}, {qubo_solution}\")\n",
    "\n",
    "    return np.array(qubo_solution), energy, circuit\n",
    "\n",
    "\n",
    "\n",
    "shape = qml.BasicEntanglerLayers.shape(n_layers=3, n_wires=n_wires)\n",
    "weights = qml.numpy.random.random(size=shape, requires_grad=True)\n",
    "\n",
    "# Configurar el optimizador\n",
    "optimizer = qml.AdamOptimizer(0.1)\n",
    "# optimizer = qml.NesterovMomentumOptimizer(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running experiment with RX rotation circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: 253.75907432373765, [1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
      "STEP 2: 251.89262567812165, [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "STEP 3: 251.71361127833754, [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "STEP 4: 251.75850206862015, [1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 5: 251.75506586046401, [1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "STEP 6: 251.6871381819785, [1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "STEP 7: 251.55811730001648, [1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "STEP 8: 251.36253512669936, [1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "STEP 9: 251.0798819420952, [1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "STEP 10: 250.67078553830748, [1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "STEP 11: 250.07603953066385, [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "STEP 12: 249.17975860581043, [1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0.]\n",
      "STEP 13: 247.7820774397689, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "STEP 14: 245.40317850278484, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "STEP 15: 241.262496049591, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "STEP 16: 234.95183704711854, [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "STEP 17: 227.04219324676868, [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 18: 219.3011066529091, [1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 19: 213.4038769297411, [1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 20: 209.19633644794513, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 21: 205.58195912861794, [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 22: 201.67251777616954, [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 23: 197.1066284002948, [1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 24: 192.01440590661397, [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 25: 186.00337588901206, [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "STEP 26: 178.13292752993112, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 27: 168.1891686282339, [1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 28: 157.3515470141914, [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 29: 147.85210201404678, [1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 30: 140.85214841115334, [1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 31: 136.04135108696215, [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 32: 132.71203072421207, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 33: 130.184242363437, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 34: 127.68137358533446, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 35: 124.48116719318264, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "STEP 36: 120.39243151351691, [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 37: 115.83623941630101, [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 38: 111.25144340998908, [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 39: 106.95958810773408, [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 40: 103.50293860223636, [1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 41: 101.15648109051884, [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 42: 99.81831024673534, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 43: 99.33536199758166, [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 44: 99.46725093449224, [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 45: 99.92128695056613, [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "STEP 46: 100.4567044294452, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 47: 100.91524929419674, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 48: 101.12535706235094, [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 49: 100.9387994538094, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 50: 100.35123808513283, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 51: 99.35426879510365, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 52: 97.72542591641394, [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 53: 94.96445910749242, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "STEP 54: 90.54985178705626, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 55: 84.42359920308837, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 56: 77.3105758633015, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 57: 70.3190529472656, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 58: 65.25448028677481, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 59: 63.0256022739259, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 60: 62.49401975597993, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 61: 62.04865926094808, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 62: 61.01629838439884, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 63: 58.822204029459726, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 64: 55.36371221054098, [1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "STEP 65: 51.473451342496276, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 66: 48.3262419078258, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 67: 45.97065219206293, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 68: 42.982993356177715, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 69: 37.80663638021181, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 70: 30.483992702158034, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 71: 23.071853158945217, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 72: 17.80608718528274, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 73: 15.10985245157133, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 74: 14.01677241398912, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "STEP 75: 13.61473998877882, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 76: 13.510932240122555, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 77: 13.666939328543547, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 78: 14.17890048187506, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 79: 15.086736354276518, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 80: 16.226308766032215, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 81: 17.249911287837413, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 82: 17.839847816139837, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "STEP 83: 17.871814005104163, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 84: 17.409110362942997, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 85: 16.629568337508942, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 86: 15.748780513194372, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 87: 14.940683302838835, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 88: 14.290369600837028, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 89: 13.79632964586589, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 90: 13.401312214426689, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 91: 13.030810113970361, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 92: 12.630253017912201, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 93: 12.194050583045065, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 94: 11.797001834333098, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "STEP 95: 11.6424133404076, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 96: 11.950143208502052, [1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "STEP 97: 12.210241518875153, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 98: 12.139148662208001, [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "STEP 99: 11.96645852562595, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "STEP 100: 11.86854807160335, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 11.86854807160335)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qubo_solution, energy, circuit = run_an_experiment(optimizer, weights, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running experiment with RY rotation circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: 270.1451722738467, [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 2: 254.5429793671955, [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 3: 246.06605355106453, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 4: 241.68871006394997, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 5: 238.1805449230455, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 6: 233.18004981787158, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 7: 225.88686065290787, [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 8: 216.38210661702217, [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 9: 204.90962538982745, [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "STEP 10: 190.68407173672065, [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qubo_solution, energy, circuit \u001b[38;5;241m=\u001b[39m \u001b[43mrun_an_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m, in \u001b[0;36mrun_an_experiment\u001b[0;34m(optimizer, weights, steps, rotation)\u001b[0m\n\u001b[1;32m     26\u001b[0m params \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m---> 29\u001b[0m     params, energy \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     final_expectation \u001b[38;5;241m=\u001b[39m circuit(params)\n\u001b[1;32m     31\u001b[0m     qubo_solution \u001b[38;5;241m=\u001b[39m ( np\u001b[38;5;241m.\u001b[39msign(final_expectation) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/optimize/gradient_descent.py:64\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    objective function value prior to the step.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     g, forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/optimize/gradient_descent.py:122\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 122\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/_grad.py:166\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 166\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/_grad.py:192\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 192\u001b[0m grad_value \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value, ans\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[0;34m(g)\u001b[0m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:21\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m toposort(end_node):\n\u001b[1;32m     20\u001b[0m     outgrad \u001b[38;5;241m=\u001b[39m outgrads\u001b[38;5;241m.\u001b[39mpop(node)\n\u001b[0;32m---> 21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m     23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m add_outgrads(outgrads\u001b[38;5;241m.\u001b[39mget(parent), ingrad)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:78\u001b[0m, in \u001b[0;36mdefvjp.<locals>.vjp_argnums.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     76\u001b[0m     vjp_0 \u001b[38;5;241m=\u001b[39m vjp_0_fun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m     vjp_1 \u001b[38;5;241m=\u001b[39m vjp_1_fun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: (\u001b[43mvjp_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, vjp_1(g))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     vjps \u001b[38;5;241m=\u001b[39m [vjps_dict[argnum](ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m argnum \u001b[38;5;129;01min\u001b[39;00m argnums]\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/numpy/numpy_vjps.py:523\u001b[0m, in \u001b[0;36mtensordot_vjp_0.<locals>.<lambda>\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensordot_vjp_0\u001b[39m(ans, A, B, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    522\u001b[0m     A_ndim, B_ndim \u001b[38;5;241m=\u001b[39m anp\u001b[38;5;241m.\u001b[39mndim(A), anp\u001b[38;5;241m.\u001b[39mndim(B)\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m G: match_complex(A, \u001b[43mtensordot_adjoint_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_ndim\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/numpy/numpy_vjps.py:489\u001b[0m, in \u001b[0;36mtensordot_adjoint_0\u001b[0;34m(B, G, axes, A_ndim, B_ndim)\u001b[0m\n\u001b[1;32m    485\u001b[0m summed_axes \u001b[38;5;241m=\u001b[39m [onp\u001b[38;5;241m.\u001b[39masarray(axes[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m A_ndim,\n\u001b[1;32m    486\u001b[0m                onp\u001b[38;5;241m.\u001b[39masarray(axes[\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m B_ndim]\n\u001b[1;32m    487\u001b[0m other_axes  \u001b[38;5;241m=\u001b[39m [onp\u001b[38;5;241m.\u001b[39mdelete(A_axes, summed_axes[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    488\u001b[0m                onp\u001b[38;5;241m.\u001b[39mdelete(B_axes, summed_axes[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m--> 489\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mG_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m perm \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39margsort(onp\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    491\u001b[0m     (other_axes[\u001b[38;5;241m0\u001b[39m], summed_axes[\u001b[38;5;241m0\u001b[39m][onp\u001b[38;5;241m.\u001b[39margsort(summed_axes[\u001b[38;5;241m1\u001b[39m])])))\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m onp\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/numpy/core/numeric.py:1120\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1117\u001b[0m oldb \u001b[38;5;241m=\u001b[39m [bs[axis] \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m notin]\n\u001b[1;32m   1119\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[0;32m-> 1120\u001b[0m bt \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewaxes_b\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewshape_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m res \u001b[38;5;241m=\u001b[39m dot(at, bt)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qubo_solution, energy, circuit = run_an_experiment(optimizer, weights, 150, qml.RY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Use QAOA to solve the QUBO.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Cost: 105.2383310579075 - Solution: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Step 1 - Cost: 16.61481078002824 - Solution: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Step 2 - Cost: 17.777174418222234 - Solution: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Step 3 - Cost: 40.36572226827514 - Solution: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Step 4 - Cost: 61.75125292214524 - Solution: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m params \u001b[38;5;241m=\u001b[39m initial_params\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 86\u001b[0m     params, cost \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqaoa_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     88\u001b[0m         final_expectation \u001b[38;5;241m=\u001b[39m qaoa_circuit(params)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/optimize/gradient_descent.py:64\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    objective function value prior to the step.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     g, forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/optimize/gradient_descent.py:122\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 122\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/_grad.py:166\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 166\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/pennylane/_grad.py:192\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 192\u001b[0m grad_value \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value, ans\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[0;34m(g)\u001b[0m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:21\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m toposort(end_node):\n\u001b[1;32m     20\u001b[0m     outgrad \u001b[38;5;241m=\u001b[39m outgrads\u001b[38;5;241m.\u001b[39mpop(node)\n\u001b[0;32m---> 21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m     23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m add_outgrads(outgrads\u001b[38;5;241m.\u001b[39mget(parent), ingrad)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/core.py:78\u001b[0m, in \u001b[0;36mdefvjp.<locals>.vjp_argnums.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     76\u001b[0m     vjp_0 \u001b[38;5;241m=\u001b[39m vjp_0_fun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m     vjp_1 \u001b[38;5;241m=\u001b[39m vjp_1_fun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: (vjp_0(g), \u001b[43mvjp_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     vjps \u001b[38;5;241m=\u001b[39m [vjps_dict[argnum](ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m argnum \u001b[38;5;129;01min\u001b[39;00m argnums]\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/numpy/numpy_vjps.py:527\u001b[0m, in \u001b[0;36mtensordot_vjp_1.<locals>.<lambda>\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensordot_vjp_1\u001b[39m(ans, A, B, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    526\u001b[0m     A_ndim, B_ndim \u001b[38;5;241m=\u001b[39m anp\u001b[38;5;241m.\u001b[39mndim(A), anp\u001b[38;5;241m.\u001b[39mndim(B)\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m G: match_complex(B, \u001b[43mtensordot_adjoint_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_ndim\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/autograd/numpy/numpy_vjps.py:516\u001b[0m, in \u001b[0;36mtensordot_adjoint_1\u001b[0;34m(A, G, axes, A_ndim, B_ndim)\u001b[0m\n\u001b[1;32m    512\u001b[0m summed_axes \u001b[38;5;241m=\u001b[39m [onp\u001b[38;5;241m.\u001b[39masarray(axes[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m A_ndim,\n\u001b[1;32m    513\u001b[0m                onp\u001b[38;5;241m.\u001b[39masarray(axes[\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m B_ndim]\n\u001b[1;32m    514\u001b[0m other_axes  \u001b[38;5;241m=\u001b[39m [onp\u001b[38;5;241m.\u001b[39mdelete(A_axes, summed_axes[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    515\u001b[0m                onp\u001b[38;5;241m.\u001b[39mdelete(B_axes, summed_axes[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m--> 516\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mother_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother_axes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m perm \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39margsort(onp\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    518\u001b[0m     (summed_axes[\u001b[38;5;241m1\u001b[39m][onp\u001b[38;5;241m.\u001b[39margsort(summed_axes[\u001b[38;5;241m0\u001b[39m])], other_axes[\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m onp\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n",
      "File \u001b[0;32m~/Desktop/Github/venv/lib/python3.12/site-packages/numpy/core/numeric.py:1121\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1119\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[1;32m   1120\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m-> 1121\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Define QUBO matrix\n",
    "Q = qubo_matrix\n",
    "num_qubits = len(Q)\n",
    "p = 3  # Number of QAOA layers\n",
    "\n",
    "\n",
    "def from_Q_to_Ising(Q, offset):\n",
    "    \"\"\"Convert the matrix Q of Eq.3 into Eq.13 elements J and h\"\"\"\n",
    "    n_qubits = len(Q)  # Get the number of qubits (variables) in the QUBO matrix\n",
    "    # Create default dictionaries to store h and pairwise interactions J\n",
    "    h = defaultdict(int)\n",
    "    J = defaultdict(int)\n",
    "\n",
    "    # Loop over each qubit (variable) in the QUBO matrix\n",
    "    for i in range(n_qubits):\n",
    "        # Update the magnetic field for qubit i based on its diagonal element in Q\n",
    "        h[(i,)] -= Q[i, i] / 2\n",
    "        # Update the offset based on the diagonal element in Q\n",
    "        offset += Q[i, i] / 2\n",
    "        # Loop over other qubits (variables) to calculate pairwise interactions\n",
    "        for j in range(i + 1, n_qubits):\n",
    "            # Update the pairwise interaction strength (J) between qubits i and j\n",
    "            J[(i, j)] += Q[i, j] / 4\n",
    "            # Update the magnetic fields for qubits i and j based on their interactions in Q\n",
    "            h[(i,)] -= Q[i, j] / 4\n",
    "            h[(j,)] -= Q[i, j] / 4\n",
    "            # Update the offset based on the interaction strength between qubits i and j\n",
    "            offset += Q[i, j] / 4\n",
    "    # Return the magnetic fields, pairwise interactions, and the updated offset\n",
    "    return h, J, offset\n",
    "\n",
    "h, J, offset = from_Q_to_Ising(Q, 0)\n",
    "\n",
    "# Define the device\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "# Define the QAOA circuit\n",
    "def qaoa_layer(gamma, beta):\n",
    "    # Apply phase separation based on Ising Hamiltonian\n",
    "    for i in range(num_qubits):\n",
    "        qml.RZ(-2 * gamma * h[i], wires=i)\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i + 1, num_qubits):\n",
    "            if J[i, j] != 0:\n",
    "                qml.CNOT(wires=[i, j])\n",
    "                qml.RZ(-2 * gamma * J[i, j], wires=j)\n",
    "                qml.CNOT(wires=[i, j])\n",
    "                \n",
    "    # Apply mixing Hamiltonian\n",
    "    for i in range(num_qubits):\n",
    "        qml.RX(2 * beta, wires=i)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qaoa_circuit(params):\n",
    "    # Apply the QAOA ansatz with p layers\n",
    "    gammas = params[:p]\n",
    "    betas = params[p:]\n",
    "    for i in range(p):\n",
    "        qaoa_layer(gammas[i], betas[i])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(num_qubits)]\n",
    "\n",
    "# Define cost function based on QUBO matrix and expectation values\n",
    "def energy_cost_function(expectation):\n",
    "    binary_solution = (np2.tanh(qml.numpy.array(expectation)) + 1) / 2\n",
    "    return np.dot(binary_solution, Q @ binary_solution)\n",
    "\n",
    "# Full QAOA cost function\n",
    "def qaoa_cost(params):\n",
    "    expectation = qaoa_circuit(params)\n",
    "    return energy_cost_function(expectation)\n",
    "\n",
    "# Initialize parameters and set up the optimizer\n",
    "initial_params = qml.numpy.random.rand(2 * p, requires_grad=True) * np.pi  # Random initial angles\n",
    "opt = qml.AdamOptimizer(stepsize=0.15)\n",
    "num_steps = 100\n",
    "\n",
    "# Optimization loop\n",
    "params = initial_params\n",
    "for step in range(num_steps):\n",
    "    params, cost = opt.step_and_cost(qaoa_cost, params)\n",
    "    if step % 1 == 0:\n",
    "        final_expectation = qaoa_circuit(params)\n",
    "        qubo_solution = ( np.sign(final_expectation) + 1 ) / 2\n",
    "        print(f\"Step {step} - Cost: {cost} - Solution: {qubo_solution}, {final_expectation}\")\n",
    "\n",
    "# Optimized parameters\n",
    "# print(\"Optimized QAOA parameters:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True),\n",
       "  tensor(-0.6415904, requires_grad=True)],\n",
       " array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_expectation ,n p.sign(final_expectation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
